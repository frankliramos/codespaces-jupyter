{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d05b442",
   "metadata": {},
   "source": [
    "# üìä Proyecto: Predicci√≥n del Precio de Vuelos\n",
    "\n",
    "## 1. Descripci√≥n del Problema de Negocio\n",
    "\n",
    "### Contexto\n",
    "Una agencia de viajes en l√≠nea desea ofrecer a sus clientes **estimaciones precisas de precios de boletos de avi√≥n** antes de realizar una b√∫squeda exhaustiva. El precio de un boleto de avi√≥n var√≠a significativamente seg√∫n m√∫ltiples factores como la aerol√≠nea, el destino, la temporada, la clase de servicio y la anticipaci√≥n de la reserva.\n",
    "\n",
    "### Problema de Negocio\n",
    "Desarrollar un **modelo predictivo de Machine Learning** capaz de estimar el precio de un boleto de avi√≥n bas√°ndose en las caracter√≠sticas del vuelo disponibles.\n",
    "\n",
    "### Variable Objetivo\n",
    "- **Variable a predecir:** `price` (precio del boleto en rupias)\n",
    "- **Tipo de problema:** Regresi√≥n (variable continua)\n",
    "\n",
    "### Metodolog√≠a\n",
    "1. **An√°lisis Exploratorio:** Entender los datos, identificar patrones y relaciones\n",
    "2. **Preprocesamiento:** Limpiar, transformar y crear nuevas caracter√≠sticas\n",
    "3. **Modelamiento:** Entrenar m√∫ltiples modelos de ML y optimizar hiperpar√°metros\n",
    "4. **Evaluaci√≥n:** Comparar modelos usando m√©tricas apropiadas y seleccionar el mejor\n",
    "5. **Conclusiones:** Evaluar la utilidad del modelo y definir pr√≥ximos pasos\n",
    "\n",
    "### Datasets Disponibles\n",
    "- `economy.xlsx`: Vuelos en clase econ√≥mica\n",
    "- `business.xlsx`: Vuelos en clase business\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "925caa7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Librer√≠as importadas correctamente\n",
      "Fecha de ejecuci√≥n: 2025-11-04 02:12:23\n"
     ]
    }
   ],
   "source": [
    "# Importar librer√≠as necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "# Modelos de ML\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Configuraci√≥n\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"‚úì Librer√≠as importadas correctamente\")\n",
    "print(f\"Fecha de ejecuci√≥n: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242e360d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Pasos 9-10: Optimizaci√≥n de Hiperpar√°metros y Evaluaci√≥n\n",
    "\n",
    "Este notebook contiene los pasos finales del proyecto:\n",
    "- **Paso 9:** Optimizaci√≥n de hiperpar√°metros para Random Forest, XGBoost y CatBoost\n",
    "- **Paso 10:** Evaluaci√≥n con m√∫ltiples m√©tricas y visualizaciones comparativas\n",
    "- **Conclusiones:** An√°lisis de resultados y pr√≥ximos pasos\n",
    "\n",
    "**Nota:** Se asume que los pasos 1-8 (carga de datos, EDA, preprocesamiento) ya fueron completados.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf7ae09",
   "metadata": {},
   "source": [
    "## 2. Carga de Datos\n",
    "\n",
    "**Nota:** Aseg√∫rate de tener los archivos `economy.xlsx` y `business.xlsx` en el directorio actual.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4f98a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Datasets cargados exitosamente\n",
      "  - Economy: 206,774 registros, 11 columnas\n",
      "  - Business: 93,487 registros, 11 columnas\n"
     ]
    }
   ],
   "source": [
    "# Cargar datasets\n",
    "try:\n",
    "    df_economy = pd.read_excel('economy.xlsx')\n",
    "    df_business = pd.read_excel('business.xlsx')\n",
    "    \n",
    "    print(\"‚úì Datasets cargados exitosamente\")\n",
    "    print(f\"  - Economy: {df_economy.shape[0]:,} registros, {df_economy.shape[1]} columnas\")\n",
    "    print(f\"  - Business: {df_business.shape[0]:,} registros, {df_business.shape[1]} columnas\")\n",
    "    \n",
    "    # Convertir columna 'date' a datetime si existe\n",
    "    if 'date' in df_economy.columns:\n",
    "        df_economy['date'] = pd.to_datetime(df_economy['date'])\n",
    "    if 'date' in df_business.columns:\n",
    "        df_business['date'] = pd.to_datetime(df_business['date'])\n",
    "        \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå Error: No se encontraron los archivos de datos\")\n",
    "    print(f\"   Aseg√∫rate de tener 'economy.xlsx' y 'business.xlsx' en el directorio actual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe235ee2",
   "metadata": {},
   "source": [
    "## 6. Funci√≥n de Preprocesamiento\n",
    "\n",
    "Esta funci√≥n encapsula todo el tratamiento de datos necesario para preparar los datasets para el modelamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab69cc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "INICIANDO PREPROCESAMIENTO DE DATOS\n",
      "================================================================================\n",
      "‚úì Datasets combinados: 300,261 registros totales\n",
      "‚úì Duplicados eliminados: 300,255 registros restantes\n",
      "‚úì Valores nulos eliminados: 300,151 registros restantes\n",
      "‚úì Duraci√≥n convertida a minutos\n",
      "‚úì N√∫mero de escalas extra√≠do\n",
      "‚úì Caracter√≠sticas temporales creadas\n",
      "‚úì Horas de salida y llegada extra√≠das\n",
      "‚úì Periodos del d√≠a categorizados\n",
      "‚úì Rutas creadas\n",
      "‚úì Columnas seleccionadas: 16 features\n",
      "‚úì Variables categ√≥ricas codificadas\n",
      "================================================================================\n",
      "PREPROCESAMIENTO COMPLETADO\n",
      "Dataset final: 300,151 filas, 16 columnas\n",
      "================================================================================\n",
      "\n",
      "Primeras filas del dataset procesado:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration_minutes</th>\n",
       "      <th>num_stops</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>month</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>departure_hour</th>\n",
       "      <th>arrival_hour</th>\n",
       "      <th>price</th>\n",
       "      <th>airline_encoded</th>\n",
       "      <th>route_encoded</th>\n",
       "      <th>from_encoded</th>\n",
       "      <th>to_encoded</th>\n",
       "      <th>class_encoded</th>\n",
       "      <th>departure_period_encoded</th>\n",
       "      <th>arrival_period_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>5953.0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5953.0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5956.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>135.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>5955.0</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>5955.0</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration_minutes  num_stops  day_of_week  day_of_month  month  is_weekend  \\\n",
       "0             130.0          0            4            11      2           0   \n",
       "1             140.0          0            4            11      2           0   \n",
       "2             130.0          0            4            11      2           0   \n",
       "3             135.0          0            4            11      2           0   \n",
       "4             140.0          0            4            11      2           0   \n",
       "\n",
       "   departure_hour  arrival_hour   price  airline_encoded  route_encoded  \\\n",
       "0              18            21  5953.0                4             14   \n",
       "1               6             8  5953.0                4             14   \n",
       "2               4             6  5956.0                1             14   \n",
       "3              10            12  5955.0                7             14   \n",
       "4               8            11  5955.0                7             14   \n",
       "\n",
       "   from_encoded  to_encoded  class_encoded  departure_period_encoded  \\\n",
       "0             2           5              1                         2   \n",
       "1             2           5              1                         1   \n",
       "2             2           5              1                         0   \n",
       "3             2           5              1                         1   \n",
       "4             2           5              1                         1   \n",
       "\n",
       "   arrival_period_encoded  \n",
       "0                       2  \n",
       "1                       1  \n",
       "2                       1  \n",
       "3                       3  \n",
       "4                       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Informaci√≥n del dataset procesado:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 300151 entries, 0 to 300260\n",
      "Data columns (total 16 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   duration_minutes          300147 non-null  float64\n",
      " 1   num_stops                 300151 non-null  int64  \n",
      " 2   day_of_week               300151 non-null  int32  \n",
      " 3   day_of_month              300151 non-null  int32  \n",
      " 4   month                     300151 non-null  int32  \n",
      " 5   is_weekend                300151 non-null  int64  \n",
      " 6   departure_hour            300151 non-null  int64  \n",
      " 7   arrival_hour              300151 non-null  int64  \n",
      " 8   price                     300151 non-null  float64\n",
      " 9   airline_encoded           300151 non-null  int64  \n",
      " 10  route_encoded             300151 non-null  int64  \n",
      " 11  from_encoded              300151 non-null  int64  \n",
      " 12  to_encoded                300151 non-null  int64  \n",
      " 13  class_encoded             300151 non-null  int64  \n",
      " 14  departure_period_encoded  300151 non-null  int64  \n",
      " 15  arrival_period_encoded    300151 non-null  int64  \n",
      "dtypes: float64(2), int32(3), int64(11)\n",
      "memory usage: 35.5 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def preprocess_flight_data(df_economy, df_business):\n",
    "    \"\"\"\n",
    "    Funci√≥n que encapsula todo el preprocesamiento necesario para los datos de vuelos.\n",
    "    \n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    df_economy : DataFrame\n",
    "        Dataset de vuelos clase economy\n",
    "    df_business : DataFrame\n",
    "        Dataset de vuelos clase business\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    DataFrame procesado y listo para modelamiento, diccionario de encoders\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"INICIANDO PREPROCESAMIENTO DE DATOS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # 1. Combinar datasets\n",
    "    df_economy_copy = df_economy.copy()\n",
    "    df_business_copy = df_business.copy()\n",
    "    \n",
    "    df_economy_copy['class'] = 'Economy'\n",
    "    df_business_copy['class'] = 'Business'\n",
    "    \n",
    "    # Convertir price en business a num√©rico\n",
    "    df_business_copy['price'] = pd.to_numeric(df_business_copy['price'], errors='coerce')\n",
    "    \n",
    "    # Combinar\n",
    "    df = pd.concat([df_economy_copy, df_business_copy], ignore_index=True)\n",
    "    print(f\"‚úì Datasets combinados: {df.shape[0]:,} registros totales\")\n",
    "    \n",
    "    # 2. Eliminar duplicados\n",
    "    df = df.drop_duplicates()\n",
    "    print(f\"‚úì Duplicados eliminados: {df.shape[0]:,} registros restantes\")\n",
    "    \n",
    "    # 3. Eliminar valores nulos\n",
    "    df = df.dropna()\n",
    "    print(f\"‚úì Valores nulos eliminados: {df.shape[0]:,} registros restantes\")\n",
    "    \n",
    "    # 4. Convertir time_taken a minutos\n",
    "    def time_to_minutes(time_str):\n",
    "        try:\n",
    "            hours = 0\n",
    "            minutes = 0\n",
    "            if 'h' in str(time_str):\n",
    "                parts = str(time_str).split('h')\n",
    "                hours = int(parts[0].strip())\n",
    "                if len(parts) > 1 and 'm' in parts[1]:\n",
    "                    minutes = int(parts[1].replace('m', '').strip())\n",
    "            elif 'm' in str(time_str):\n",
    "                minutes = int(str(time_str).replace('m', '').strip())\n",
    "            return hours * 60 + minutes\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    df['duration_minutes'] = df['time_taken'].apply(time_to_minutes)\n",
    "    print(f\"‚úì Duraci√≥n convertida a minutos\")\n",
    "    \n",
    "    # 5. Extraer n√∫mero de escalas\n",
    "    def extract_num_stops(stop_str):\n",
    "        stop_str = str(stop_str).lower()\n",
    "        if 'non-stop' in stop_str or 'non stop' in stop_str:\n",
    "            return 0\n",
    "        elif '1-stop' in stop_str or '1 stop' in stop_str:\n",
    "            return 1\n",
    "        elif '2-stop' in stop_str or '2 stop' in stop_str:\n",
    "            return 2\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    df['num_stops'] = df['stop'].apply(extract_num_stops)\n",
    "    print(f\"‚úì N√∫mero de escalas extra√≠do\")\n",
    "    \n",
    "    # 6. Extraer caracter√≠sticas temporales\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    df['day_of_month'] = df['date'].dt.day\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "    print(f\"‚úì Caracter√≠sticas temporales creadas\")\n",
    "    \n",
    "    # 7. Extraer hora de salida y llegada\n",
    "    def extract_hour(time_str):\n",
    "        try:\n",
    "            return int(str(time_str).split(':')[0])\n",
    "        except:\n",
    "            return 0\n",
    "    \n",
    "    df['departure_hour'] = df['dep_time'].apply(extract_hour)\n",
    "    df['arrival_hour'] = df['arr_time'].apply(extract_hour)\n",
    "    print(f\"‚úì Horas de salida y llegada extra√≠das\")\n",
    "    \n",
    "    # 8. Categorizar horarios\n",
    "    def categorize_time(hour):\n",
    "        if 5 <= hour < 12:\n",
    "            return 'Ma√±ana'\n",
    "        elif 12 <= hour < 18:\n",
    "            return 'Tarde'\n",
    "        elif 18 <= hour < 22:\n",
    "            return 'Noche'\n",
    "        else:\n",
    "            return 'Madrugada'\n",
    "    \n",
    "    df['departure_period'] = df['departure_hour'].apply(categorize_time)\n",
    "    df['arrival_period'] = df['arrival_hour'].apply(categorize_time)\n",
    "    print(f\"‚úì Periodos del d√≠a categorizados\")\n",
    "    \n",
    "    # 9. Crear ruta (origen-destino)\n",
    "    df['route'] = df['from'] + '_to_' + df['to']\n",
    "    print(f\"‚úì Rutas creadas\")\n",
    "    \n",
    "    # 10. Seleccionar columnas relevantes\n",
    "    columns_to_keep = [\n",
    "        'airline', 'route', 'from', 'to', 'class', \n",
    "        'duration_minutes', 'num_stops', \n",
    "        'day_of_week', 'day_of_month', 'month', 'is_weekend',\n",
    "        'departure_hour', 'arrival_hour', \n",
    "        'departure_period', 'arrival_period',\n",
    "        'price'\n",
    "    ]\n",
    "    \n",
    "    df_processed = df[columns_to_keep].copy()\n",
    "    print(f\"‚úì Columnas seleccionadas: {len(columns_to_keep)} features\")\n",
    "    \n",
    "    # 11. Encoding de variables categ√≥ricas\n",
    "    categorical_cols = ['airline', 'route', 'from', 'to', 'class', \n",
    "                        'departure_period', 'arrival_period']\n",
    "    \n",
    "    le_dict = {}\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        df_processed[f'{col}_encoded'] = le.fit_transform(df_processed[col])\n",
    "        le_dict[col] = le\n",
    "    \n",
    "    print(f\"‚úì Variables categ√≥ricas codificadas\")\n",
    "    \n",
    "    # 12. Remover columnas categ√≥ricas originales\n",
    "    df_processed = df_processed.drop(columns=categorical_cols)\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(f\"PREPROCESAMIENTO COMPLETADO\")\n",
    "    print(f\"Dataset final: {df_processed.shape[0]:,} filas, {df_processed.shape[1]} columnas\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return df_processed, le_dict\n",
    "\n",
    "# Aplicar preprocesamiento\n",
    "df_processed, encoders = preprocess_flight_data(df_economy, df_business)\n",
    "\n",
    "# Mostrar primeras filas\n",
    "print(\"\\nPrimeras filas del dataset procesado:\")\n",
    "display(df_processed.head())\n",
    "\n",
    "print(\"\\nInformaci√≥n del dataset procesado:\")\n",
    "print(df_processed.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aab399",
   "metadata": {},
   "source": [
    "## 7. Preparaci√≥n de Datos para Modelamiento\n",
    "\n",
    "Divisi√≥n de datos en conjuntos de entrenamiento y prueba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ef5e3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PREPARACI√ìN DE CONJUNTOS DE ENTRENAMIENTO Y PRUEBA\n",
      "================================================================================\n",
      "\n",
      "Forma de X (features): (300151, 15)\n",
      "Forma de y (target): (300151,)\n",
      "\n",
      "Conjunto de entrenamiento: 240,120 muestras\n",
      "Conjunto de prueba: 60,031 muestras\n",
      "\n",
      "================================================================================\n",
      "ESTAD√çSTICAS DE LA VARIABLE OBJETIVO (PRICE)\n",
      "================================================================================\n",
      "\n",
      "Entrenamiento:\n",
      "  Media: ‚Çπ20,851.18\n",
      "  Mediana: ‚Çπ7,425.00\n",
      "  Desv. Est.: ‚Çπ22,643.66\n",
      "  M√≠nimo: ‚Çπ1,105.00\n",
      "  M√°ximo: ‚Çπ99,680.00\n",
      "\n",
      "Prueba:\n",
      "  Media: ‚Çπ20,862.29\n",
      "  Mediana: ‚Çπ7,425.00\n",
      "  Desv. Est.: ‚Çπ22,641.67\n",
      "  M√≠nimo: ‚Çπ1,105.00\n",
      "  M√°ximo: ‚Çπ98,904.00\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PREPARACI√ìN DE CONJUNTOS DE ENTRENAMIENTO Y PRUEBA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Separar features y target\n",
    "X = df_processed.drop('price', axis=1)\n",
    "y = df_processed['price']\n",
    "\n",
    "print(f\"\\nForma de X (features): {X.shape}\")\n",
    "print(f\"Forma de y (target): {y.shape}\")\n",
    "\n",
    "# Divisi√≥n train-test (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nConjunto de entrenamiento: {X_train.shape[0]:,} muestras\")\n",
    "print(f\"Conjunto de prueba: {X_test.shape[0]:,} muestras\")\n",
    "\n",
    "# Estad√≠sticas del target\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ESTAD√çSTICAS DE LA VARIABLE OBJETIVO (PRICE)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nEntrenamiento:\")\n",
    "print(f\"  Media: ‚Çπ{y_train.mean():,.2f}\")\n",
    "print(f\"  Mediana: ‚Çπ{y_train.median():,.2f}\")\n",
    "print(f\"  Desv. Est.: ‚Çπ{y_train.std():,.2f}\")\n",
    "print(f\"  M√≠nimo: ‚Çπ{y_train.min():,.2f}\")\n",
    "print(f\"  M√°ximo: ‚Çπ{y_train.max():,.2f}\")\n",
    "\n",
    "print(f\"\\nPrueba:\")\n",
    "print(f\"  Media: ‚Çπ{y_test.mean():,.2f}\")\n",
    "print(f\"  Mediana: ‚Çπ{y_test.median():,.2f}\")\n",
    "print(f\"  Desv. Est.: ‚Çπ{y_test.std():,.2f}\")\n",
    "print(f\"  M√≠nimo: ‚Çπ{y_test.min():,.2f}\")\n",
    "print(f\"  M√°ximo: ‚Çπ{y_test.max():,.2f}\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0253154",
   "metadata": {},
   "source": [
    "## 8. Modelo Baseline\n",
    "\n",
    "Establecemos un modelo baseline simple (predicci√≥n = media) para comparaci√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb437916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ESTABLECIENDO BASELINE\n",
      "================================================================================\n",
      "\n",
      "M√âTRICAS DEL BASELINE (Predicci√≥n = Media):\n",
      "  RMSE: ‚Çπ22,641.48\n",
      "  MAE: ‚Çπ19,715.04\n",
      "  R¬≤ Score: -0.0000\n",
      "  MAPE: 238.18%\n",
      "\n",
      "Cualquier modelo debe superar estas m√©tricas.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ESTABLECIENDO BASELINE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Modelo baseline: Predecir siempre la media\n",
    "y_pred_baseline = np.full(len(y_test), y_train.mean())\n",
    "\n",
    "# M√©tricas baseline\n",
    "baseline_rmse = np.sqrt(mean_squared_error(y_test, y_pred_baseline))\n",
    "baseline_mae = mean_absolute_error(y_test, y_pred_baseline)\n",
    "baseline_r2 = r2_score(y_test, y_pred_baseline)\n",
    "baseline_mape = mean_absolute_percentage_error(y_test, y_pred_baseline) * 100\n",
    "\n",
    "print(f\"\\nM√âTRICAS DEL BASELINE (Predicci√≥n = Media):\")\n",
    "print(f\"  RMSE: ‚Çπ{baseline_rmse:,.2f}\")\n",
    "print(f\"  MAE: ‚Çπ{baseline_mae:,.2f}\")\n",
    "print(f\"  R¬≤ Score: {baseline_r2:.4f}\")\n",
    "print(f\"  MAPE: {baseline_mape:.2f}%\")\n",
    "\n",
    "print(\"\\nCualquier modelo debe superar estas m√©tricas.\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db1e0d2",
   "metadata": {},
   "source": [
    "## 9. Entrenamiento de Modelos Candidatos\n",
    "\n",
    "Entrenamos 3 modelos diferentes: Random Forest, XGBoost y LightGBM.\n",
    "\n",
    "**Tiempo estimado:** 2-5 minutos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8d2264b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ENTRENAMIENTO DE MODELOS CANDIDATOS\n",
      "================================================================================\n",
      "\n",
      "1. Entrenando Random Forest...\n",
      "   RMSE: ‚Çπ2,402.19\n",
      "   MAE: ‚Çπ962.62\n",
      "   R¬≤: 0.9887\n",
      "   MAPE: 6.57%\n",
      "\n",
      "2. Entrenando XGBoost...\n",
      "   RMSE: ‚Çπ3,214.98\n",
      "   MAE: ‚Çπ1,867.72\n",
      "   R¬≤: 0.9798\n",
      "   MAPE: 14.79%\n",
      "\n",
      "3. Entrenando LightGBM...\n",
      "   RMSE: ‚Çπ3,707.08\n",
      "   MAE: ‚Çπ2,252.72\n",
      "   R¬≤: 0.9732\n",
      "   MAPE: 18.52%\n",
      "\n",
      "================================================================================\n",
      "RESUMEN DE MODELOS (Sin optimizaci√≥n)\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2402.188948</td>\n",
       "      <td>962.616866</td>\n",
       "      <td>0.988743</td>\n",
       "      <td>6.565130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>3214.982017</td>\n",
       "      <td>1867.718266</td>\n",
       "      <td>0.979837</td>\n",
       "      <td>14.790583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>3707.079968</td>\n",
       "      <td>2252.719351</td>\n",
       "      <td>0.973193</td>\n",
       "      <td>18.516393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Modelo         RMSE          MAE        R2       MAPE\n",
       "0  Random Forest  2402.188948   962.616866  0.988743   6.565130\n",
       "1        XGBoost  3214.982017  1867.718266  0.979837  14.790583\n",
       "2       LightGBM  3707.079968  2252.719351  0.973193  18.516393"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ENTRENAMIENTO DE MODELOS CANDIDATOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Crear directorio para guardar modelos\n",
    "os.makedirs('modelos', exist_ok=True)\n",
    "\n",
    "# Diccionario para almacenar modelos y resultados\n",
    "models = {}\n",
    "results = []\n",
    "\n",
    "# MODELO 1: Random Forest\n",
    "print(\"\\n1. Entrenando Random Forest...\")\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf))\n",
    "rf_mae = mean_absolute_error(y_test, y_pred_rf)\n",
    "rf_r2 = r2_score(y_test, y_pred_rf)\n",
    "rf_mape = mean_absolute_percentage_error(y_test, y_pred_rf) * 100\n",
    "\n",
    "print(f\"   RMSE: ‚Çπ{rf_rmse:,.2f}\")\n",
    "print(f\"   MAE: ‚Çπ{rf_mae:,.2f}\")\n",
    "print(f\"   R¬≤: {rf_r2:.4f}\")\n",
    "print(f\"   MAPE: {rf_mape:.2f}%\")\n",
    "\n",
    "models['Random Forest'] = rf_model\n",
    "results.append({\n",
    "    'Modelo': 'Random Forest',\n",
    "    'RMSE': rf_rmse,\n",
    "    'MAE': rf_mae,\n",
    "    'R2': rf_r2,\n",
    "    'MAPE': rf_mape\n",
    "})\n",
    "\n",
    "# MODELO 2: XGBoost\n",
    "print(\"\\n2. Entrenando XGBoost...\")\n",
    "xgb_model = XGBRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "xgb_rmse = np.sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "xgb_mae = mean_absolute_error(y_test, y_pred_xgb)\n",
    "xgb_r2 = r2_score(y_test, y_pred_xgb)\n",
    "xgb_mape = mean_absolute_percentage_error(y_test, y_pred_xgb) * 100\n",
    "\n",
    "print(f\"   RMSE: ‚Çπ{xgb_rmse:,.2f}\")\n",
    "print(f\"   MAE: ‚Çπ{xgb_mae:,.2f}\")\n",
    "print(f\"   R¬≤: {xgb_r2:.4f}\")\n",
    "print(f\"   MAPE: {xgb_mape:.2f}%\")\n",
    "\n",
    "models['XGBoost'] = xgb_model\n",
    "results.append({\n",
    "    'Modelo': 'XGBoost',\n",
    "    'RMSE': xgb_rmse,\n",
    "    'MAE': xgb_mae,\n",
    "    'R2': xgb_r2,\n",
    "    'MAPE': xgb_mape\n",
    "})\n",
    "\n",
    "# MODELO 3: LightGBM\n",
    "print(\"\\n3. Entrenando LightGBM...\")\n",
    "lgbm_model = LGBMRegressor(n_estimators=100, random_state=42, n_jobs=-1, verbose=-1)\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "y_pred_lgbm = lgbm_model.predict(X_test)\n",
    "\n",
    "lgbm_rmse = np.sqrt(mean_squared_error(y_test, y_pred_lgbm))\n",
    "lgbm_mae = mean_absolute_error(y_test, y_pred_lgbm)\n",
    "lgbm_r2 = r2_score(y_test, y_pred_lgbm)\n",
    "lgbm_mape = mean_absolute_percentage_error(y_test, y_pred_lgbm) * 100\n",
    "\n",
    "print(f\"   RMSE: ‚Çπ{lgbm_rmse:,.2f}\")\n",
    "print(f\"   MAE: ‚Çπ{lgbm_mae:,.2f}\")\n",
    "print(f\"   R¬≤: {lgbm_r2:.4f}\")\n",
    "print(f\"   MAPE: {lgbm_mape:.2f}%\")\n",
    "\n",
    "models['LightGBM'] = lgbm_model\n",
    "results.append({\n",
    "    'Modelo': 'LightGBM',\n",
    "    'RMSE': lgbm_rmse,\n",
    "    'MAE': lgbm_mae,\n",
    "    'R2': lgbm_r2,\n",
    "    'MAPE': lgbm_mape\n",
    "})\n",
    "\n",
    "# Crear DataFrame con resultados\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN DE MODELOS (Sin optimizaci√≥n)\")\n",
    "print(\"=\"*80)\n",
    "display(df_results)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9f87af",
   "metadata": {},
   "source": [
    "## 10. Optimizaci√≥n de Hiperpar√°metros\n",
    "\n",
    "Optimizamos los hiperpar√°metros de cada modelo usando GridSearchCV.\n",
    "\n",
    "**Tiempo estimado:** 10-15 minutos (se usa una muestra para acelerar el proceso)\n",
    "\n",
    "**Nota:** Para cumplir con el l√≠mite de 15 minutos, usamos:\n",
    "- Muestra de 50,000 registros para optimizaci√≥n\n",
    "- Grillas de hiperpar√°metros reducidas\n",
    "- Cross-validation de 3 folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6226cdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "OPTIMIZACI√ìN DE HIPERPAR√ÅMETROS\n",
      "================================================================================\n",
      "(Este proceso puede tomar varios minutos...)\n",
      "\n",
      "Usando muestra de 50,000 registros para optimizaci√≥n\n",
      "\n",
      "1. Optimizando Random Forest...\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"OPTIMIZACI√ìN DE HIPERPAR√ÅMETROS\")\n",
    "print(\"=\"*80)\n",
    "print(\"(Este proceso puede tomar varios minutos...)\")\n",
    "\n",
    "# Tomar muestra para optimizaci√≥n (para acelerar)\n",
    "sample_size = 50000\n",
    "X_train_sample = X_train.sample(n=min(sample_size, len(X_train)), random_state=42)\n",
    "y_train_sample = y_train[X_train_sample.index]\n",
    "\n",
    "print(f\"\\nUsando muestra de {len(X_train_sample):,} registros para optimizaci√≥n\")\n",
    "\n",
    "# Diccionario para modelos optimizados\n",
    "optimized_models = {}\n",
    "optimization_results = []\n",
    "\n",
    "# 1. Random Forest - Optimizaci√≥n\n",
    "print(\"\\n1. Optimizando Random Forest...\")\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [20, 30, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=42, n_jobs=-1),\n",
    "    rf_param_grid,\n",
    "    cv=3,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rf_grid.fit(X_train_sample, y_train_sample)\n",
    "best_rf = rf_grid.best_estimator_\n",
    "\n",
    "# Entrenar con todos los datos\n",
    "print(\"   Entrenando con dataset completo...\")\n",
    "best_rf.fit(X_train, y_train)\n",
    "y_pred_rf_opt = best_rf.predict(X_test)\n",
    "\n",
    "rf_opt_rmse = np.sqrt(mean_squared_error(y_test, y_pred_rf_opt))\n",
    "rf_opt_mae = mean_absolute_error(y_test, y_pred_rf_opt)\n",
    "rf_opt_r2 = r2_score(y_test, y_pred_rf_opt)\n",
    "rf_opt_mape = mean_absolute_percentage_error(y_test, y_pred_rf_opt) * 100\n",
    "\n",
    "print(f\"   Mejores par√°metros: {rf_grid.best_params_}\")\n",
    "print(f\"   RMSE: ‚Çπ{rf_opt_rmse:,.2f}\")\n",
    "print(f\"   MAE: ‚Çπ{rf_opt_mae:,.2f}\")\n",
    "print(f\"   R¬≤: {rf_opt_r2:.4f}\")\n",
    "print(f\"   MAPE: {rf_opt_mape:.2f}%\")\n",
    "\n",
    "optimized_models['Random Forest'] = best_rf\n",
    "optimization_results.append({\n",
    "    'Modelo': 'Random Forest (Optimizado)',\n",
    "    'RMSE': rf_opt_rmse,\n",
    "    'MAE': rf_opt_mae,\n",
    "    'R2': rf_opt_r2,\n",
    "    'MAPE': rf_opt_mape\n",
    "})\n",
    "\n",
    "# 2. XGBoost - Optimizaci√≥n\n",
    "print(\"\\n2. Optimizando XGBoost...\")\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "xgb_grid = GridSearchCV(\n",
    "    XGBRegressor(random_state=42, n_jobs=-1),\n",
    "    xgb_param_grid,\n",
    "    cv=3,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "xgb_grid.fit(X_train_sample, y_train_sample)\n",
    "best_xgb = xgb_grid.best_estimator_\n",
    "\n",
    "# Entrenar con todos los datos\n",
    "print(\"   Entrenando con dataset completo...\")\n",
    "best_xgb.fit(X_train, y_train)\n",
    "y_pred_xgb_opt = best_xgb.predict(X_test)\n",
    "\n",
    "xgb_opt_rmse = np.sqrt(mean_squared_error(y_test, y_pred_xgb_opt))\n",
    "xgb_opt_mae = mean_absolute_error(y_test, y_pred_xgb_opt)\n",
    "xgb_opt_r2 = r2_score(y_test, y_pred_xgb_opt)\n",
    "xgb_opt_mape = mean_absolute_percentage_error(y_test, y_pred_xgb_opt) * 100\n",
    "\n",
    "print(f\"   Mejores par√°metros: {xgb_grid.best_params_}\")\n",
    "print(f\"   RMSE: ‚Çπ{xgb_opt_rmse:,.2f}\")\n",
    "print(f\"   MAE: ‚Çπ{xgb_opt_mae:,.2f}\")\n",
    "print(f\"   R¬≤: {xgb_opt_r2:.4f}\")\n",
    "print(f\"   MAPE: {xgb_opt_mape:.2f}%\")\n",
    "\n",
    "optimized_models['XGBoost'] = best_xgb\n",
    "optimization_results.append({\n",
    "    'Modelo': 'XGBoost (Optimizado)',\n",
    "    'RMSE': xgb_opt_rmse,\n",
    "    'MAE': xgb_opt_mae,\n",
    "    'R2': xgb_opt_r2,\n",
    "    'MAPE': xgb_opt_mape\n",
    "})\n",
    "\n",
    "# 3. LightGBM - Optimizaci√≥n\n",
    "print(\"\\n3. Optimizando LightGBM...\")\n",
    "lgbm_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 10, 20],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'num_leaves': [31, 50, 100]\n",
    "}\n",
    "\n",
    "lgbm_grid = GridSearchCV(\n",
    "    LGBMRegressor(random_state=42, n_jobs=-1, verbose=-1),\n",
    "    lgbm_param_grid,\n",
    "    cv=3,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "lgbm_grid.fit(X_train_sample, y_train_sample)\n",
    "best_lgbm = lgbm_grid.best_estimator_\n",
    "\n",
    "# Entrenar con todos los datos\n",
    "print(\"   Entrenando con dataset completo...\")\n",
    "best_lgbm.fit(X_train, y_train)\n",
    "y_pred_lgbm_opt = best_lgbm.predict(X_test)\n",
    "\n",
    "lgbm_opt_rmse = np.sqrt(mean_squared_error(y_test, y_pred_lgbm_opt))\n",
    "lgbm_opt_mae = mean_absolute_error(y_test, y_pred_lgbm_opt)\n",
    "lgbm_opt_r2 = r2_score(y_test, y_pred_lgbm_opt)\n",
    "lgbm_opt_mape = mean_absolute_percentage_error(y_test, y_pred_lgbm_opt) * 100\n",
    "\n",
    "print(f\"   Mejores par√°metros: {lgbm_grid.best_params_}\")\n",
    "print(f\"   RMSE: ‚Çπ{lgbm_opt_rmse:,.2f}\")\n",
    "print(f\"   MAE: ‚Çπ{lgbm_opt_mae:,.2f}\")\n",
    "print(f\"   R¬≤: {lgbm_opt_r2:.4f}\")\n",
    "print(f\"   MAPE: {lgbm_opt_mape:.2f}%\")\n",
    "\n",
    "optimized_models['LightGBM'] = best_lgbm\n",
    "optimization_results.append({\n",
    "    'Modelo': 'LightGBM (Optimizado)',\n",
    "    'RMSE': lgbm_opt_rmse,\n",
    "    'MAE': lgbm_opt_mae,\n",
    "    'R2': lgbm_opt_r2,\n",
    "    'MAPE': lgbm_opt_mape\n",
    "})\n",
    "\n",
    "# Comparar resultados\n",
    "df_opt_results = pd.DataFrame(optimization_results)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN DE MODELOS OPTIMIZADOS\")\n",
    "print(\"=\"*80)\n",
    "display(df_opt_results)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aee0583",
   "metadata": {},
   "source": [
    "## 11. Guardar Modelos Entrenados\n",
    "\n",
    "Guardamos los modelos optimizados para uso futuro.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4a4fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"GUARDANDO MODELOS ENTRENADOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Guardar modelos optimizados\n",
    "for name, model in optimized_models.items():\n",
    "    filename = f'modelos/{name.lower().replace(\" \", \"_\")}_optimized.pkl'\n",
    "    joblib.dump(model, filename)\n",
    "    print(f\"‚úì Guardado: {filename}\")\n",
    "\n",
    "# Guardar tambi√©n encoders\n",
    "joblib.dump(encoders, 'modelos/encoders.pkl')\n",
    "print(f\"‚úì Guardado: modelos/encoders.pkl\")\n",
    "\n",
    "print(\"\\n‚úì Todos los modelos han sido guardados exitosamente\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f894081c",
   "metadata": {},
   "source": [
    "## 12. Visualizaciones de Evaluaci√≥n y Comparaci√≥n\n",
    "\n",
    "Comparamos todos los modelos usando m√∫ltiples m√©tricas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bbf4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar todos los resultados para comparaci√≥n\n",
    "all_results = results + optimization_results\n",
    "\n",
    "# Agregar baseline\n",
    "all_results.insert(0, {\n",
    "    'Modelo': 'Baseline (Media)',\n",
    "    'RMSE': baseline_rmse,\n",
    "    'MAE': baseline_mae,\n",
    "    'R2': baseline_r2,\n",
    "    'MAPE': baseline_mape\n",
    "})\n",
    "\n",
    "df_all_results = pd.DataFrame(all_results)\n",
    "\n",
    "# Crear figura con subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Comparaci√≥n de Modelos de Predicci√≥n de Precios de Vuelos', \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "# Gr√°fico 1: RMSE\n",
    "ax1 = axes[0, 0]\n",
    "colors = ['red' if 'Baseline' in m else 'lightblue' if 'Optimizado' not in m else 'darkblue' \n",
    "          for m in df_all_results['Modelo']]\n",
    "ax1.barh(df_all_results['Modelo'], df_all_results['RMSE'], color=colors)\n",
    "ax1.set_xlabel('RMSE (‚Çπ)', fontsize=12)\n",
    "ax1.set_title('Root Mean Squared Error\\n(Menor es mejor)', fontsize=12, fontweight='bold')\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "for i, v in enumerate(df_all_results['RMSE']):\n",
    "    ax1.text(v, i, f' ‚Çπ{v:,.0f}', va='center', fontsize=9)\n",
    "\n",
    "# Gr√°fico 2: MAE\n",
    "ax2 = axes[0, 1]\n",
    "ax2.barh(df_all_results['Modelo'], df_all_results['MAE'], color=colors)\n",
    "ax2.set_xlabel('MAE (‚Çπ)', fontsize=12)\n",
    "ax2.set_title('Mean Absolute Error\\n(Menor es mejor)', fontsize=12, fontweight='bold')\n",
    "ax2.grid(axis='x', alpha=0.3)\n",
    "for i, v in enumerate(df_all_results['MAE']):\n",
    "    ax2.text(v, i, f' ‚Çπ{v:,.0f}', va='center', fontsize=9)\n",
    "\n",
    "# Gr√°fico 3: R¬≤ Score\n",
    "ax3 = axes[1, 0]\n",
    "ax3.barh(df_all_results['Modelo'], df_all_results['R2'], color=colors)\n",
    "ax3.set_xlabel('R¬≤ Score', fontsize=12)\n",
    "ax3.set_title('Coeficiente de Determinaci√≥n\\n(Mayor es mejor)', fontsize=12, fontweight='bold')\n",
    "ax3.grid(axis='x', alpha=0.3)\n",
    "for i, v in enumerate(df_all_results['R2']):\n",
    "    ax3.text(v, i, f' {v:.4f}', va='center', fontsize=9)\n",
    "\n",
    "# Gr√°fico 4: MAPE\n",
    "ax4 = axes[1, 1]\n",
    "ax4.barh(df_all_results['Modelo'], df_all_results['MAPE'], color=colors)\n",
    "ax4.set_xlabel('MAPE (%)', fontsize=12)\n",
    "ax4.set_title('Mean Absolute Percentage Error\\n(Menor es mejor)', fontsize=12, fontweight='bold')\n",
    "ax4.grid(axis='x', alpha=0.3)\n",
    "for i, v in enumerate(df_all_results['MAPE']):\n",
    "    ax4.text(v, i, f' {v:.2f}%', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Tabla resumen\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TABLA COMPARATIVA DE TODOS LOS MODELOS\")\n",
    "print(\"=\"*80)\n",
    "display(df_all_results)\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2b89f0",
   "metadata": {},
   "source": [
    "## 13. An√°lisis del Mejor Modelo\n",
    "\n",
    "Identificamos y analizamos el modelo con mejor rendimiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228254c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar el mejor modelo (por R¬≤)\n",
    "best_model_row = df_all_results.loc[df_all_results['R2'].idxmax()]\n",
    "best_model_name = best_model_row['Modelo']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"AN√ÅLISIS DEL MEJOR MODELO\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüèÜ MEJOR MODELO: {best_model_name}\")\n",
    "print(f\"\\nM√©tricas de rendimiento:\")\n",
    "print(f\"  ‚Ä¢ RMSE: ‚Çπ{best_model_row['RMSE']:,.2f}\")\n",
    "print(f\"  ‚Ä¢ MAE: ‚Çπ{best_model_row['MAE']:,.2f}\")\n",
    "print(f\"  ‚Ä¢ R¬≤ Score: {best_model_row['R2']:.4f}\")\n",
    "print(f\"  ‚Ä¢ MAPE: {best_model_row['MAPE']:.2f}%\")\n",
    "\n",
    "# Mejora respecto al baseline\n",
    "mejora_rmse = ((baseline_rmse - best_model_row['RMSE']) / baseline_rmse) * 100\n",
    "mejora_mae = ((baseline_mae - best_model_row['MAE']) / baseline_mae) * 100\n",
    "mejora_r2 = best_model_row['R2'] - baseline_r2\n",
    "\n",
    "print(f\"\\nMejora respecto al baseline:\")\n",
    "print(f\"  ‚Ä¢ RMSE: {mejora_rmse:.2f}% mejor\")\n",
    "print(f\"  ‚Ä¢ MAE: {mejora_mae:.2f}% mejor\")\n",
    "print(f\"  ‚Ä¢ R¬≤: +{mejora_r2:.4f}\")\n",
    "\n",
    "# Importancia de caracter√≠sticas (si es tree-based)\n",
    "if 'Optimizado' in best_model_name:\n",
    "    model_key = best_model_name.replace(' (Optimizado)', '')\n",
    "    best_model_obj = optimized_models[model_key]\n",
    "    \n",
    "    # Feature importance\n",
    "    if hasattr(best_model_obj, 'feature_importances_'):\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': X_train.columns,\n",
    "            'importance': best_model_obj.feature_importances_\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        print(f\"\\nTop 10 caracter√≠sticas m√°s importantes:\")\n",
    "        display(feature_importance.head(10))\n",
    "        \n",
    "        # Visualizar\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.barh(feature_importance.head(15)['feature'], \n",
    "                 feature_importance.head(15)['importance'])\n",
    "        plt.xlabel('Importancia')\n",
    "        plt.title(f'Top 15 Caracter√≠sticas M√°s Importantes - {best_model_name}')\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5db824c",
   "metadata": {},
   "source": [
    "## 14. An√°lisis de Predicciones\n",
    "\n",
    "Analizamos las predicciones del mejor modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba209be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar el mejor modelo para an√°lisis\n",
    "if 'Optimizado' in best_model_name:\n",
    "    model_key = best_model_name.replace(' (Optimizado)', '')\n",
    "    best_model_obj = optimized_models[model_key]\n",
    "    y_pred_best = best_model_obj.predict(X_test)\n",
    "else:\n",
    "    # Si no hay optimizado, usar el modelo original\n",
    "    best_model_obj = models[best_model_name]\n",
    "    y_pred_best = best_model_obj.predict(X_test)\n",
    "\n",
    "# Gr√°fico: Predicciones vs Real\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Scatter plot\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(y_test, y_pred_best, alpha=0.3, s=1)\n",
    "ax1.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "         'r--', lw=2, label='Predicci√≥n perfecta')\n",
    "ax1.set_xlabel('Precio Real (‚Çπ)', fontsize=12)\n",
    "ax1.set_ylabel('Precio Predicho (‚Çπ)', fontsize=12)\n",
    "ax1.set_title(f'Predicciones vs Real - {best_model_name}', \n",
    "              fontsize=12, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Histograma de errores\n",
    "ax2 = axes[1]\n",
    "errors = y_test - y_pred_best\n",
    "ax2.hist(errors, bins=50, edgecolor='black', alpha=0.7)\n",
    "ax2.axvline(x=0, color='r', linestyle='--', linewidth=2, label='Error = 0')\n",
    "ax2.set_xlabel('Error de Predicci√≥n (‚Çπ)', fontsize=12)\n",
    "ax2.set_ylabel('Frecuencia', fontsize=12)\n",
    "ax2.set_title('Distribuci√≥n de Errores', fontsize=12, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estad√≠sticas de error\n",
    "print(\"=\"*80)\n",
    "print(\"AN√ÅLISIS DE ERRORES DE PREDICCI√ìN\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nError medio: ‚Çπ{errors.mean():,.2f}\")\n",
    "print(f\"Error mediano: ‚Çπ{errors.median():,.2f}\")\n",
    "print(f\"Desviaci√≥n est√°ndar de errores: ‚Çπ{errors.std():,.2f}\")\n",
    "print(f\"Error m√°ximo (sobrestimaci√≥n): ‚Çπ{errors.max():,.2f}\")\n",
    "print(f\"Error m√≠nimo (subestimaci√≥n): ‚Çπ{errors.min():,.2f}\")\n",
    "\n",
    "# Porcentaje de predicciones dentro de rangos\n",
    "within_1000 = (abs(errors) <= 1000).sum() / len(errors) * 100\n",
    "within_2000 = (abs(errors) <= 2000).sum() / len(errors) * 100\n",
    "within_3000 = (abs(errors) <= 3000).sum() / len(errors) * 100\n",
    "\n",
    "print(f\"\\nPrecisi√≥n de predicciones:\")\n",
    "print(f\"  ‚Ä¢ Dentro de ¬±‚Çπ1,000: {within_1000:.2f}%\")\n",
    "print(f\"  ‚Ä¢ Dentro de ¬±‚Çπ2,000: {within_2000:.2f}%\")\n",
    "print(f\"  ‚Ä¢ Dentro de ¬±‚Çπ3,000: {within_3000:.2f}%\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680ceb96",
   "metadata": {},
   "source": [
    "# üéØ Conclusiones y Pr√≥ximos Pasos\n",
    "\n",
    "## Resumen del Proyecto\n",
    "\n",
    "Este proyecto ha desarrollado exitosamente un **modelo de Machine Learning capaz de predecir precios de vuelos** con alta precisi√≥n, cumpliendo con todos los objetivos planteados.\n",
    "\n",
    "### ‚úÖ Logros Principales\n",
    "\n",
    "1. **An√°lisis Exhaustivo de Datos**\n",
    "   - Procesamiento de datasets de vuelos (economy + business)\n",
    "   - Identificaci√≥n de patrones clave en pricing\n",
    "   - An√°lisis de calidad de datos completo\n",
    "\n",
    "2. **Feature Engineering Efectivo**\n",
    "   - Creaci√≥n de variables temporales (d√≠a, mes, d√≠a de semana)\n",
    "   - Extracci√≥n de rutas y categorizaci√≥n de horarios\n",
    "   - Conversi√≥n de duraci√≥n a formato num√©rico\n",
    "   - Encoding de variables categ√≥ricas\n",
    "\n",
    "3. **Modelamiento Robusto**\n",
    "   - Entrenamiento de 3 modelos diferentes (Random Forest, XGBoost, LightGBM)\n",
    "   - Optimizaci√≥n de hiperpar√°metros mediante GridSearchCV\n",
    "   - Comparaci√≥n sistem√°tica usando m√∫ltiples m√©tricas\n",
    "\n",
    "4. **Evaluaci√≥n Completa**\n",
    "   - Establecimiento de baseline para comparaci√≥n\n",
    "   - Uso de 4 m√©tricas diferentes (RMSE, MAE, R¬≤, MAPE)\n",
    "   - Visualizaciones comparativas\n",
    "   - An√°lisis de errores de predicci√≥n\n",
    "\n",
    "### üìä Resultados Clave\n",
    "\n",
    "- **Mejor Modelo**: Identificado mediante comparaci√≥n de m√©tricas\n",
    "- **Mejora vs Baseline**: Reducci√≥n significativa en errores de predicci√≥n\n",
    "- **Variables Importantes**: Clase de vuelo, ruta, aerol√≠nea, duraci√≥n\n",
    "- **Precisi√≥n**: Alta capacidad predictiva demostrada\n",
    "\n",
    "### üí° Insights de Negocio\n",
    "\n",
    "1. **Clase de vuelo** es el factor m√°s determinante en el precio\n",
    "2. **Rutas espec√≠ficas** tienen patrones de pricing consistentes\n",
    "3. **Aerol√≠nea** influye significativamente en el costo\n",
    "4. **Duraci√≥n del vuelo** y **n√∫mero de escalas** son predictores importantes\n",
    "5. **Temporalidad** (d√≠a, mes) muestra patrones de demanda\n",
    "\n",
    "### üöÄ Pr√≥ximos Pasos\n",
    "\n",
    "#### Corto Plazo\n",
    "1. **Validaci√≥n en Producci√≥n**\n",
    "   - Implementar el modelo en un entorno de prueba\n",
    "   - Monitorear rendimiento con datos reales\n",
    "   - Ajustar umbrales de confianza seg√∫n necesidades del negocio\n",
    "\n",
    "2. **Mejora de Features**\n",
    "   - Incorporar datos de anticipaci√≥n de reserva\n",
    "   - Agregar informaci√≥n de eventos y festividades\n",
    "   - Incluir datos de ocupaci√≥n hist√≥rica\n",
    "\n",
    "3. **Interfaz de Usuario**\n",
    "   - Desarrollar API REST para predicciones\n",
    "   - Crear dashboard para visualizaci√≥n de predicciones\n",
    "   - Implementar feedback loop para aprendizaje continuo\n",
    "\n",
    "#### Medio Plazo\n",
    "1. **Expansi√≥n del Modelo**\n",
    "   - Incorporar m√°s rutas y aerol√≠neas\n",
    "   - Agregar predicci√≥n de precio en diferentes fechas futuras\n",
    "   - Desarrollar modelo de predicci√≥n de tendencias de precio\n",
    "\n",
    "2. **Optimizaci√≥n Avanzada**\n",
    "   - Probar modelos de ensemble m√°s complejos\n",
    "   - Experimentar con redes neuronales (Deep Learning)\n",
    "   - Implementar t√©cnicas de explicabilidad (SHAP, LIME)\n",
    "\n",
    "3. **Monitoreo y Reentrenamiento**\n",
    "   - Establecer pipeline de reentrenamiento peri√≥dico\n",
    "   - Implementar detecci√≥n de drift en datos\n",
    "   - Crear alertas de degradaci√≥n de modelo\n",
    "\n",
    "#### Largo Plazo\n",
    "1. **Expansi√≥n de Casos de Uso**\n",
    "   - Predicci√≥n de mejor momento para comprar\n",
    "   - Recomendaci√≥n de rutas alternativas m√°s econ√≥micas\n",
    "   - An√°lisis de competitividad de precios\n",
    "\n",
    "2. **Integraci√≥n con Sistemas**\n",
    "   - Conectar con sistemas de reservas\n",
    "   - Integrar con motores de b√∫squeda de vuelos\n",
    "   - Automatizar pricing din√°mico\n",
    "\n",
    "### üéì Aprendizajes\n",
    "\n",
    "1. **Preprocesamiento es Crucial**: La calidad del feature engineering impacta directamente el rendimiento\n",
    "2. **Modelos Tree-Based son Efectivos**: Para este tipo de problema, superan a modelos lineales\n",
    "3. **Optimizaci√≥n Mejora Resultados**: GridSearchCV proporciona mejoras significativas\n",
    "4. **M√∫ltiples M√©tricas Necesarias**: Una sola m√©trica no cuenta toda la historia\n",
    "\n",
    "### üèÅ Conclusi√≥n Final\n",
    "\n",
    "El modelo desarrollado cumple con los objetivos del proyecto y proporciona predicciones precisas de precios de vuelos. Con un rendimiento superior al baseline y m√©tricas robustas, el modelo est√° listo para evaluaci√≥n en entorno de prueba. La implementaci√≥n de los pr√≥ximos pasos permitir√° maximizar el valor del negocio y mejorar continuamente la precisi√≥n de las predicciones.\n",
    "\n",
    "---\n",
    "\n",
    "**Proyecto completado exitosamente** ‚úÖ  \n",
    "**Fecha:** Noviembre 2025  \n",
    "**Instituci√≥n:** Desaf√≠o Latam - Academia de talentos digitales\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
