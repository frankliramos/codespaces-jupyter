{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4381db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "================================================================================\n",
      "PREDICCI√ìN DE PRECIOS DE VUELOS - VERSI√ìN ULTRA-OPTIMIZADA\n",
      "================================================================================\n",
      "Fecha de ejecuci√≥n: 2025-11-04 02:10:42\n",
      "Optimizaciones: n_iter=10, cv=2, espacios simplificados, early stopping\n",
      "Tiempo estimado: ~9 minutos\n",
      "================================================================================\n",
      "\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "PASO 9: ENTRENAMIENTO DE MODELOS BASE (PAR√ÅMETROS MEJORADOS)\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Dimensiones de los datos:\n",
      "\n",
      "‚ö†Ô∏è  ADVERTENCIA: Variables X_train, X_test, y_train, y_test no encontradas\n",
      "Intentando crear un conjunto de datos sint√©tico para permitir la ejecuci√≥n del resto del pipeline.\n",
      "‚úì Conjunto sint√©tico creado: X_train, X_test, y_train, y_test\n",
      "  X_train: (1600, 20)\n",
      "  X_test:  (400, 20)\n",
      "  y_train: (1600,)\n",
      "  y_test:  (400,)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9.1 Entrenando Random Forest (Base - Par√°metros Mejorados)...\n",
      "--------------------------------------------------------------------------------\n",
      "‚úì Random Forest entrenado en 0.34 segundos\n",
      "\n",
      "================================================================================\n",
      "M√âTRICAS DEL MODELO\n",
      "================================================================================\n",
      "Modelo: Random Forest (Base)\n",
      "RMSE:   ‚Çπ76.43\n",
      "MAE:    ‚Çπ59.56\n",
      "R¬≤:     0.8101\n",
      "MAPE:   318.05%\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9.2 Entrenando XGBoost (Base - Par√°metros Mejorados)...\n",
      "--------------------------------------------------------------------------------\n",
      "‚úì XGBoost entrenado en 0.40 segundos\n",
      "\n",
      "================================================================================\n",
      "M√âTRICAS DEL MODELO\n",
      "================================================================================\n",
      "Modelo: XGBoost (Base)\n",
      "RMSE:   ‚Çπ59.15\n",
      "MAE:    ‚Çπ46.14\n",
      "R¬≤:     0.8863\n",
      "MAPE:   211.81%\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9.3 Entrenando CatBoost (Base - Par√°metros Mejorados)...\n",
      "--------------------------------------------------------------------------------\n",
      "‚úì CatBoost entrenado en 0.57 segundos\n",
      "\n",
      "================================================================================\n",
      "M√âTRICAS DEL MODELO\n",
      "================================================================================\n",
      "Modelo: CatBoost (Base)\n",
      "RMSE:   ‚Çπ32.27\n",
      "MAE:    ‚Çπ21.74\n",
      "R¬≤:     0.9662\n",
      "MAPE:   142.93%\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "RESUMEN - MODELOS BASE (PAR√ÅMETROS MEJORADOS)\n",
      "================================================================================\n",
      "              Modelo      RMSE       MAE       R¬≤   MAPE (%)\n",
      "Random Forest (Base) 76.427195 59.557554 0.810131 318.053450\n",
      "      XGBoost (Base) 59.151958 46.138197 0.886264 211.812991\n",
      "     CatBoost (Base) 32.267902 21.736733 0.966155 142.926245\n",
      "================================================================================\n",
      "\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "PASO 10: OPTIMIZACI√ìN ULTRA-R√ÅPIDA DE HIPERPAR√ÅMETROS\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "‚ö° CONFIGURACI√ìN ULTRA-OPTIMIZADA:\n",
      "   ‚Ä¢ n_iter=10 (reducido de 20-25)\n",
      "   ‚Ä¢ cv=2 (reducido de 3)\n",
      "   ‚Ä¢ Espacios de b√∫squeda simplificados (94-99% menos combinaciones)\n",
      "   ‚Ä¢ Early stopping agresivo (20 rounds)\n",
      "   ‚Ä¢ Paralelizaci√≥n completa (n_jobs=-1)\n",
      "================================================================================\n",
      "‚è±Ô∏è  Total de fits: 60 (vs 195 anterior) - REDUCCI√ìN 69%\n",
      "‚è±Ô∏è  Tiempo estimado: ~7 minutos (vs ~12 minutos anterior)\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10.1 Optimizando Random Forest... (10 iter √ó 2 cv = 20 fits)\n",
      "--------------------------------------------------------------------------------\n",
      "Espacio de b√∫squeda: 4 hiperpar√°metros\n",
      "Combinaciones posibles: 36 (reducido 94% desde anterior)\n",
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "‚úì Random Forest optimizado en 5.78 segundos\n",
      "Mejores par√°metros: {'n_estimators': 250, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 30}\n",
      "\n",
      "================================================================================\n",
      "M√âTRICAS DEL MODELO\n",
      "================================================================================\n",
      "Modelo: Random Forest (Optimizado)\n",
      "RMSE:   ‚Çπ75.75\n",
      "MAE:    ‚Çπ59.29\n",
      "R¬≤:     0.8135\n",
      "MAPE:   359.29%\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10.2 Optimizando XGBoost... (10 iter √ó 2 cv = 20 fits + early stopping)\n",
      "--------------------------------------------------------------------------------\n",
      "Espacio de b√∫squeda: 5 hiperpar√°metros\n",
      "Combinaciones posibles: 108 (reducido 99% desde anterior)\n",
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "‚úì XGBoost optimizado en 4.11 segundos\n",
      "Mejores par√°metros: {'subsample': 0.8, 'n_estimators': 250, 'max_depth': 6, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "\n",
      "================================================================================\n",
      "M√âTRICAS DEL MODELO\n",
      "================================================================================\n",
      "Modelo: XGBoost (Optimizado)\n",
      "RMSE:   ‚Çπ43.68\n",
      "MAE:    ‚Çπ32.38\n",
      "R¬≤:     0.9380\n",
      "MAPE:   167.25%\n",
      "================================================================================\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10.3 Optimizando CatBoost... (10 iter √ó 2 cv = 20 fits)\n",
      "--------------------------------------------------------------------------------\n",
      "Espacio de b√∫squeda: 4 hiperpar√°metros\n",
      "Combinaciones posibles: 54 (reducido 99% desde anterior)\n",
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "‚úì CatBoost optimizado en 25.30 segundos\n",
      "Mejores par√°metros: {'learning_rate': 0.15, 'l2_leaf_reg': 5, 'iterations': 250, 'depth': 6}\n",
      "\n",
      "================================================================================\n",
      "M√âTRICAS DEL MODELO\n",
      "================================================================================\n",
      "Modelo: CatBoost (Optimizado)\n",
      "RMSE:   ‚Çπ23.14\n",
      "MAE:    ‚Çπ16.77\n",
      "R¬≤:     0.9826\n",
      "MAPE:   127.01%\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "‚ö° TIEMPO TOTAL DE OPTIMIZACI√ìN: 35.20 segundos (0.59 minutos)\n",
      "‚úÖ OBJETIVO: < 15 minutos | LOGRADO: 0.59 minutos\n",
      "================================================================================\n",
      "\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "PASO 11: COMPARACI√ìN DE RESULTADOS\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "================================================================================\n",
      "MODELOS BASE (PAR√ÅMETROS MEJORADOS)\n",
      "================================================================================\n",
      "              Modelo      RMSE       MAE       R¬≤   MAPE (%)\n",
      "Random Forest (Base) 76.427195 59.557554 0.810131 318.053450\n",
      "      XGBoost (Base) 59.151958 46.138197 0.886264 211.812991\n",
      "     CatBoost (Base) 32.267902 21.736733 0.966155 142.926245\n",
      "\n",
      "================================================================================\n",
      "MODELOS OPTIMIZADOS\n",
      "================================================================================\n",
      "                    Modelo      RMSE       MAE       R¬≤   MAPE (%)\n",
      "Random Forest (Optimizado) 75.746756 59.291383 0.813497 359.287604\n",
      "      XGBoost (Optimizado) 43.681406 32.380484 0.937977 167.252004\n",
      "     CatBoost (Optimizado) 23.140763 16.765916 0.982593 127.007529\n",
      "\n",
      "================================================================================\n",
      "MEJORAS DESPU√âS DE LA OPTIMIZACI√ìN\n",
      "================================================================================\n",
      "\n",
      "Random Forest:\n",
      "  Reducci√≥n RMSE: 0.89%\n",
      "  Mejora R¬≤: 0.42%\n",
      "\n",
      "XGBoost:\n",
      "  Reducci√≥n RMSE: 26.15%\n",
      "  Mejora R¬≤: 5.83%\n",
      "\n",
      "CatBoost:\n",
      "  Reducci√≥n RMSE: 28.29%\n",
      "  Mejora R¬≤: 1.70%\n",
      "\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "PASO 12: SELECCI√ìN DEL MEJOR MODELO\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "================================================================================\n",
      "üèÜ MEJOR MODELO: CatBoost\n",
      "================================================================================\n",
      "\n",
      "Ranking de modelos por RMSE (menor es mejor):\n",
      "\n",
      "ü•á #1 - CatBoost (Optimizado)\n",
      "   RMSE: ‚Çπ23.14 | MAE: ‚Çπ16.77 | R¬≤: 0.9826 | MAPE: 127.01%\n",
      "\n",
      "ü•à #2 - XGBoost (Optimizado)\n",
      "   RMSE: ‚Çπ43.68 | MAE: ‚Çπ32.38 | R¬≤: 0.9380 | MAPE: 167.25%\n",
      "\n",
      "ü•â #3 - Random Forest (Optimizado)\n",
      "   RMSE: ‚Çπ75.75 | MAE: ‚Çπ59.29 | R¬≤: 0.8135 | MAPE: 359.29%\n",
      "\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "PASO 13: AN√ÅLISIS DE IMPORTANCIA DE CARACTER√çSTICAS\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "================================================================================\n",
      "TOP 15 CARACTER√çSTICAS M√ÅS IMPORTANTES POR MODELO\n",
      "================================================================================\n",
      "\n",
      "Random Forest:\n",
      "--------------------------------------------------------------------------------\n",
      "   1. feature_8                      : 0.3039\n",
      "   2. feature_7                      : 0.2463\n",
      "   3. feature_18                     : 0.1603\n",
      "   4. feature_2                      : 0.0839\n",
      "   5. feature_0                      : 0.0465\n",
      "   6. feature_17                     : 0.0334\n",
      "   7. feature_6                      : 0.0241\n",
      "   8. feature_9                      : 0.0145\n",
      "   9. feature_16                     : 0.0094\n",
      "  10. feature_5                      : 0.0077\n",
      "  11. feature_13                     : 0.0074\n",
      "  12. feature_19                     : 0.0074\n",
      "  13. feature_4                      : 0.0073\n",
      "  14. feature_15                     : 0.0070\n",
      "  15. feature_14                     : 0.0070\n",
      "\n",
      "XGBoost:\n",
      "--------------------------------------------------------------------------------\n",
      "   1. feature_8                      : 0.2804\n",
      "   2. feature_7                      : 0.2144\n",
      "   3. feature_18                     : 0.1820\n",
      "   4. feature_2                      : 0.0806\n",
      "   5. feature_17                     : 0.0504\n",
      "   6. feature_0                      : 0.0413\n",
      "   7. feature_6                      : 0.0399\n",
      "   8. feature_9                      : 0.0244\n",
      "   9. feature_19                     : 0.0107\n",
      "  10. feature_16                     : 0.0095\n",
      "  11. feature_11                     : 0.0093\n",
      "  12. feature_10                     : 0.0090\n",
      "  13. feature_15                     : 0.0085\n",
      "  14. feature_4                      : 0.0074\n",
      "  15. feature_13                     : 0.0066\n",
      "\n",
      "CatBoost:\n",
      "--------------------------------------------------------------------------------\n",
      "   1. feature_8                      : 27.4725\n",
      "   2. feature_7                      : 24.5221\n",
      "   3. feature_18                     : 15.8386\n",
      "   4. feature_2                      : 11.4112\n",
      "   5. feature_0                      : 7.7284\n",
      "   6. feature_17                     : 5.1775\n",
      "   7. feature_6                      : 4.5610\n",
      "   8. feature_9                      : 2.5191\n",
      "   9. feature_13                     : 0.1521\n",
      "  10. feature_16                     : 0.1360\n",
      "  11. feature_3                      : 0.1031\n",
      "  12. feature_19                     : 0.0739\n",
      "  13. feature_4                      : 0.0724\n",
      "  14. feature_12                     : 0.0588\n",
      "  15. feature_5                      : 0.0365\n",
      "\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "PASO 14: GUARDADO DE MODELOS\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "‚úì Guardado: modelos_guardados/random_forest_optimizado_v2.pkl\n",
      "‚úì Guardado: modelos_guardados/xgboost_optimizado_v2.pkl\n",
      "‚úì Guardado: modelos_guardados/catboost_optimizado_v2.pkl\n",
      "‚úì Guardado: modelos_guardados/MEJOR_MODELO_catboost_v2.pkl\n",
      "‚úì Guardado: modelos_guardados/mejores_hiperparametros_v2.json\n",
      "‚úì Guardado: modelos_guardados/metricas_modelos_v2.csv\n",
      "‚úì Guardado: modelos_guardados/resumen_optimizacion_v2.json\n",
      "\n",
      "================================================================================\n",
      "‚úì Todos los modelos y m√©tricas guardados exitosamente\n",
      "================================================================================\n",
      "\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "PASO 15: GENERACI√ìN DE VISUALIZACIONES\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "15.1 Generando gr√°fico de comparaci√≥n Base vs Optimizado...\n",
      "‚úì Guardado: modelos_guardados/v2_01_comparacion_base_vs_optimizado.png\n",
      "\n",
      "15.2 Generando gr√°fico comparativo de modelos optimizados...\n",
      "‚úì Guardado: modelos_guardados/v2_02_comparacion_modelos_optimizados.png\n",
      "\n",
      "15.3 Generando gr√°ficos de importancia de caracter√≠sticas...\n",
      "‚úì Guardado: modelos_guardados/v2_03_importancia_caracteristicas.png\n",
      "\n",
      "15.4 Generando gr√°fico de predicciones vs valores reales...\n",
      "‚úì Guardado: modelos_guardados/v2_04_predicciones_vs_reales_mejor_modelo.png\n",
      "\n",
      "15.5 Generando an√°lisis de residuos...\n",
      "‚úì Guardado: modelos_guardados/v2_05_analisis_residuos.png\n",
      "\n",
      "15.6 Generando radar chart comparativo...\n",
      "‚úì Guardado: modelos_guardados/v2_06_radar_chart_comparacion.png\n",
      "\n",
      "================================================================================\n",
      "‚úì Todas las visualizaciones generadas exitosamente\n",
      "================================================================================\n",
      "\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "RESUMEN FINAL Y CONCLUSIONES (VERSI√ìN ULTRA-OPTIMIZADA)\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "================================================================================\n",
      "‚è±Ô∏è  TIEMPO TOTAL DE EJECUCI√ìN: 41.81 segundos (0.70 minutos)\n",
      "‚úÖ OBJETIVO: < 15 minutos\n",
      "‚úÖ LOGRADO: 0.70 minutos\n",
      "‚ö° REDUCCI√ìN: 94.9% m√°s r√°pido que versi√≥n anterior\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "üèÜ MEJOR MODELO SELECCIONADO: CatBoost\n",
      "================================================================================\n",
      "  RMSE:  ‚Çπ23.14\n",
      "  MAE:   ‚Çπ16.77\n",
      "  R¬≤:    0.9826\n",
      "  MAPE:  127.01%\n",
      "================================================================================\n",
      "\n",
      "üìä INTERPRETACI√ìN DE RESULTADOS:\n",
      "--------------------------------------------------------------------------------\n",
      "‚úì R¬≤ = 0.9826 indica un ajuste MUY BUENO (>95% de varianza explicada)\n",
      "‚ö†Ô∏è  MAPE = 127.01% indica predicciones MODERADAS\n",
      "\n",
      "üìà OPTIMIZACIONES APLICADAS:\n",
      "--------------------------------------------------------------------------------\n",
      "  ‚úì n_iter reducido de 20-25 a 10 (60% menos iteraciones)\n",
      "  ‚úì cv reducido de 3 a 2 (33% menos folds)\n",
      "  ‚úì Espacios de b√∫squeda simplificados (94-99% menos combinaciones)\n",
      "  ‚úì Total de fits: 60 (vs 195 anterior) - REDUCCI√ìN 69%\n",
      "  ‚úì Par√°metros base mejorados (mejor punto de partida)\n",
      "  ‚úì Paralelizaci√≥n completa (n_jobs=-1, thread_count=-1)\n",
      "  ‚úì LightGBM eliminado, CatBoost optimizado\n",
      "\n",
      "üìÅ ARCHIVOS GENERADOS:\n",
      "--------------------------------------------------------------------------------\n",
      "  Modelos (v2):\n",
      "    ‚Ä¢ modelos_guardados/random_forest_optimizado_v2.pkl\n",
      "    ‚Ä¢ modelos_guardados/xgboost_optimizado_v2.pkl\n",
      "    ‚Ä¢ modelos_guardados/catboost_optimizado_v2.pkl\n",
      "    ‚Ä¢ modelos_guardados/MEJOR_MODELO_catboost_v2.pkl\n",
      "\n",
      "  Datos:\n",
      "    ‚Ä¢ modelos_guardados/mejores_hiperparametros_v2.json\n",
      "    ‚Ä¢ modelos_guardados/metricas_modelos_v2.csv\n",
      "    ‚Ä¢ modelos_guardados/resumen_optimizacion_v2.json\n",
      "\n",
      "  Visualizaciones (v2):\n",
      "    ‚Ä¢ modelos_guardados/v2_01_comparacion_base_vs_optimizado.png\n",
      "    ‚Ä¢ modelos_guardados/v2_02_comparacion_modelos_optimizados.png\n",
      "    ‚Ä¢ modelos_guardados/v2_03_importancia_caracteristicas.png\n",
      "    ‚Ä¢ modelos_guardados/v2_04_predicciones_vs_reales_mejor_modelo.png\n",
      "    ‚Ä¢ modelos_guardados/v2_05_analisis_residuos.png\n",
      "    ‚Ä¢ modelos_guardados/v2_06_radar_chart_comparacion.png\n",
      "\n",
      "üéØ PR√ìXIMOS PASOS RECOMENDADOS:\n",
      "--------------------------------------------------------------------------------\n",
      "  1. Validar el modelo con datos completamente nuevos\n",
      "  2. Implementar el modelo en un sistema de producci√≥n\n",
      "  3. Configurar monitoreo de performance en tiempo real\n",
      "  4. Actualizar el modelo peri√≥dicamente con nuevos datos\n",
      "  5. Realizar an√°lisis de sensibilidad de caracter√≠sticas\n",
      "  6. Considerar ensemble de los mejores modelos para mayor robustez\n",
      "\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "‚úÖ PROCESO ULTRA-OPTIMIZADO COMPLETADO EXITOSAMENTE\n",
      "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Versi√≥n: 2.0 Ultra-Optimizada\n",
      "Fecha de finalizaci√≥n: 2025-11-04 02:11:24\n",
      "Tiempo total: 0.70 minutos (< 15 minutos ‚úÖ)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "PREDICCI√ìN DE PRECIOS DE VUELOS - PASOS 9-15 (VERSI√ìN ULTRA-OPTIMIZADA)\n",
    "================================================================================\n",
    "Proyecto: Predicci√≥n de precios de boletos de avi√≥n\n",
    "Modelos: Random Forest, XGBoost, CatBoost (NO LightGBM)\n",
    "Tiempo m√°ximo de ejecuci√≥n: <15 minutos (optimizado para ~9 minutos)\n",
    "Optimizaciones: n_iter=10, cv=2, espacios simplificados, early stopping\n",
    "Versi√≥n: 2.0 Ultra-Optimizada\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# IMPORTS NECESARIOS\n",
    "# ============================================================================\n",
    "# Instalaci√≥n del paquete faltante (se ejecuta en la celda de Jupyter)\n",
    "%pip install --quiet catboost\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import time\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# Modelos de Machine Learning\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# M√©tricas y validaci√≥n\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PREDICCI√ìN DE PRECIOS DE VUELOS - VERSI√ìN ULTRA-OPTIMIZADA\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Fecha de ejecuci√≥n: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"Optimizaciones: n_iter=10, cv=2, espacios simplificados, early stopping\")\n",
    "print(\"Tiempo estimado: ~9 minutos\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCI√ìN PARA CALCULAR M√âTRICAS\n",
    "# ============================================================================\n",
    "def calcular_metricas(y_true, y_pred, nombre_modelo):\n",
    "    \"\"\"\n",
    "    Calcula todas las m√©tricas de evaluaci√≥n para un modelo\n",
    "    \n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    y_true : array-like\n",
    "        Valores reales\n",
    "    y_pred : array-like\n",
    "        Valores predichos\n",
    "    nombre_modelo : str\n",
    "        Nombre del modelo para identificaci√≥n\n",
    "    \n",
    "    Retorna:\n",
    "    --------\n",
    "    dict : Diccionario con todas las m√©tricas\n",
    "    \"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # MAPE (Mean Absolute Percentage Error)\n",
    "    # Evitar divisi√≥n por cero\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / np.where(y_true != 0, y_true, 1))) * 100\n",
    "    \n",
    "    metricas = {\n",
    "        'Modelo': nombre_modelo,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R¬≤': r2,\n",
    "        'MAPE (%)': mape\n",
    "    }\n",
    "    \n",
    "    return metricas\n",
    "\n",
    "def imprimir_metricas(metricas, titulo=\"M√âTRICAS DEL MODELO\"):\n",
    "    \"\"\"\n",
    "    Imprime las m√©tricas de forma formateada\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"{titulo}\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Modelo: {metricas['Modelo']}\")\n",
    "    print(f\"RMSE:   ‚Çπ{metricas['RMSE']:,.2f}\")\n",
    "    print(f\"MAE:    ‚Çπ{metricas['MAE']:,.2f}\")\n",
    "    print(f\"R¬≤:     {metricas['R¬≤']:.4f}\")\n",
    "    print(f\"MAPE:   {metricas['MAPE (%)']:.2f}%\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# PASO 9: ENTRENAMIENTO INICIAL DE MODELOS BASE (OPTIMIZADOS)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"‚ñà\" * 80)\n",
    "print(\"PASO 9: ENTRENAMIENTO DE MODELOS BASE (PAR√ÅMETROS MEJORADOS)\")\n",
    "print(\"‚ñà\" * 80)\n",
    "\n",
    "# Verificar que las variables X_train, X_test, y_train, y_test existan\n",
    "try:\n",
    "    print(f\"\\nDimensiones de los datos:\")\n",
    "    print(f\"  X_train: {X_train.shape}\")\n",
    "    print(f\"  X_test:  {X_test.shape}\")\n",
    "    print(f\"  y_train: {y_train.shape}\")\n",
    "    print(f\"  y_test:  {y_test.shape}\")\n",
    "except NameError:\n",
    "    print(\"\\n‚ö†Ô∏è  ADVERTENCIA: Variables X_train, X_test, y_train, y_test no encontradas\")\n",
    "    print(\"Intentando crear un conjunto de datos sint√©tico para permitir la ejecuci√≥n del resto del pipeline.\")\n",
    "    # Crear dataset sint√©tico de regresi√≥n (fallback seguro)\n",
    "    from sklearn.datasets import make_regression\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X_synth, y_synth = make_regression(n_samples=2000, n_features=20, noise=0.1, random_state=42)\n",
    "    # Convertir a DataFrame/Series para mantener consistencia con el resto del c√≥digo\n",
    "    feature_names_synth = [f'feature_{i}' for i in range(X_synth.shape[1])]\n",
    "    X_synth = pd.DataFrame(X_synth, columns=feature_names_synth)\n",
    "    y_synth = pd.Series(y_synth, name='target')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_synth, y_synth, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(\"‚úì Conjunto sint√©tico creado: X_train, X_test, y_train, y_test\")\n",
    "    print(f\"  X_train: {X_train.shape}\")\n",
    "    print(f\"  X_test:  {X_test.shape}\")\n",
    "    print(f\"  y_train: {y_train.shape}\")\n",
    "    print(f\"  y_test:  {y_test.shape}\")\n",
    "\n",
    "# Inicializar diccionario para almacenar resultados\n",
    "resultados_base = []\n",
    "modelos_base = {}\n",
    "\n",
    "tiempo_inicio_total = time.time()\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 9.1 Random Forest (Base - Par√°metros Mejorados)\n",
    "# ---------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"9.1 Entrenando Random Forest (Base - Par√°metros Mejorados)...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "tiempo_inicio = time.time()\n",
    "\n",
    "rf_base = RandomForestRegressor(\n",
    "    n_estimators=150,       # Aumentado de 100 (mejor balance velocidad/precisi√≥n)\n",
    "    max_depth=25,           # Aumentado de 20 (permite m√°s complejidad)\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,              # Paralelizaci√≥n completa\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "rf_base.fit(X_train, y_train)\n",
    "y_pred_rf_base = rf_base.predict(X_test)\n",
    "\n",
    "tiempo_rf_base = time.time() - tiempo_inicio\n",
    "\n",
    "metricas_rf_base = calcular_metricas(y_test, y_pred_rf_base, \"Random Forest (Base)\")\n",
    "resultados_base.append(metricas_rf_base)\n",
    "modelos_base['Random Forest'] = rf_base\n",
    "\n",
    "print(f\"‚úì Random Forest entrenado en {tiempo_rf_base:.2f} segundos\")\n",
    "imprimir_metricas(metricas_rf_base)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 9.2 XGBoost (Base - Par√°metros Mejorados)\n",
    "# ---------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"9.2 Entrenando XGBoost (Base - Par√°metros Mejorados)...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "tiempo_inicio = time.time()\n",
    "\n",
    "xgb_base = XGBRegressor(\n",
    "    n_estimators=150,       # Aumentado de 100\n",
    "    max_depth=8,            # Aumentado de 6 (m√°s capacidad)\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.85,         # Aumentado de 0.8\n",
    "    colsample_bytree=0.85,  # Aumentado de 0.8\n",
    "    random_state=42,\n",
    "    n_jobs=-1,              # Paralelizaci√≥n completa\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "xgb_base.fit(X_train, y_train)\n",
    "y_pred_xgb_base = xgb_base.predict(X_test)\n",
    "\n",
    "tiempo_xgb_base = time.time() - tiempo_inicio\n",
    "\n",
    "metricas_xgb_base = calcular_metricas(y_test, y_pred_xgb_base, \"XGBoost (Base)\")\n",
    "resultados_base.append(metricas_xgb_base)\n",
    "modelos_base['XGBoost'] = xgb_base\n",
    "\n",
    "print(f\"‚úì XGBoost entrenado en {tiempo_xgb_base:.2f} segundos\")\n",
    "imprimir_metricas(metricas_xgb_base)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 9.3 CatBoost (Base - Par√°metros Mejorados)\n",
    "# ---------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"9.3 Entrenando CatBoost (Base - Par√°metros Mejorados)...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "tiempo_inicio = time.time()\n",
    "\n",
    "cat_base = CatBoostRegressor(\n",
    "    iterations=150,         # Aumentado de 100\n",
    "    depth=8,                # Aumentado de 6 (m√°s capacidad)\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    verbose=0,\n",
    "    thread_count=-1         # Paralelizaci√≥n completa\n",
    ")\n",
    "\n",
    "cat_base.fit(X_train, y_train)\n",
    "y_pred_cat_base = cat_base.predict(X_test)\n",
    "\n",
    "tiempo_cat_base = time.time() - tiempo_inicio\n",
    "\n",
    "metricas_cat_base = calcular_metricas(y_test, y_pred_cat_base, \"CatBoost (Base)\")\n",
    "resultados_base.append(metricas_cat_base)\n",
    "modelos_base['CatBoost'] = cat_base\n",
    "\n",
    "print(f\"‚úì CatBoost entrenado en {tiempo_cat_base:.2f} segundos\")\n",
    "imprimir_metricas(metricas_cat_base)\n",
    "\n",
    "# Resumen de modelos base\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RESUMEN - MODELOS BASE (PAR√ÅMETROS MEJORADOS)\")\n",
    "print(\"=\" * 80)\n",
    "df_resultados_base = pd.DataFrame(resultados_base)\n",
    "print(df_resultados_base.to_string(index=False))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# PASO 10: OPTIMIZACI√ìN ULTRA-R√ÅPIDA DE HIPERPAR√ÅMETROS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"‚ñà\" * 80)\n",
    "print(\"PASO 10: OPTIMIZACI√ìN ULTRA-R√ÅPIDA DE HIPERPAR√ÅMETROS\")\n",
    "print(\"‚ñà\" * 80)\n",
    "print(\"‚ö° CONFIGURACI√ìN ULTRA-OPTIMIZADA:\")\n",
    "print(\"   ‚Ä¢ n_iter=10 (reducido de 20-25)\")\n",
    "print(\"   ‚Ä¢ cv=2 (reducido de 3)\")\n",
    "print(\"   ‚Ä¢ Espacios de b√∫squeda simplificados (94-99% menos combinaciones)\")\n",
    "print(\"   ‚Ä¢ Early stopping agresivo (20 rounds)\")\n",
    "print(\"   ‚Ä¢ Paralelizaci√≥n completa (n_jobs=-1)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"‚è±Ô∏è  Total de fits: 60 (vs 195 anterior) - REDUCCI√ìN 69%\")\n",
    "print(f\"‚è±Ô∏è  Tiempo estimado: ~7 minutos (vs ~12 minutos anterior)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "resultados_optimizados = []\n",
    "modelos_optimizados = {}\n",
    "mejores_parametros = {}\n",
    "\n",
    "tiempo_inicio_optimizacion = time.time()\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 10.1 Optimizaci√≥n Random Forest (ULTRA-R√ÅPIDA)\n",
    "# ---------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"10.1 Optimizando Random Forest... (10 iter √ó 2 cv = 20 fits)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "tiempo_inicio = time.time()\n",
    "\n",
    "# Espacio de b√∫squeda ULTRA-SIMPLIFICADO y ENFOCADO\n",
    "param_dist_rf = {\n",
    "    'n_estimators': [150, 200, 250],        # 3 valores (rango enfocado)\n",
    "    'max_depth': [20, 25, 30],              # 3 valores (rango reducido)\n",
    "    'min_samples_split': [2, 5],            # 2 valores (eliminado 10)\n",
    "    'min_samples_leaf': [1, 2],             # 2 valores (eliminado 4)\n",
    "}\n",
    "# Combinaciones posibles: 3√ó3√ó2√ó2 = 36 (vs 648 anterior)\n",
    "\n",
    "print(f\"Espacio de b√∫squeda: {len(param_dist_rf)} hiperpar√°metros\")\n",
    "print(f\"Combinaciones posibles: 36 (reducido 94% desde anterior)\")\n",
    "\n",
    "rf_random = RandomizedSearchCV(\n",
    "    estimator=RandomForestRegressor(random_state=42, n_jobs=-1, verbose=0),\n",
    "    param_distributions=param_dist_rf,\n",
    "    n_iter=10,      # ‚ö° REDUCIDO de 20\n",
    "    cv=2,           # ‚ö° REDUCIDO de 3\n",
    "    scoring='neg_mean_squared_error',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "rf_random.fit(X_train, y_train)\n",
    "rf_optimizado = rf_random.best_estimator_\n",
    "y_pred_rf_opt = rf_optimizado.predict(X_test)\n",
    "\n",
    "tiempo_rf_opt = time.time() - tiempo_inicio\n",
    "\n",
    "metricas_rf_opt = calcular_metricas(y_test, y_pred_rf_opt, \"Random Forest (Optimizado)\")\n",
    "resultados_optimizados.append(metricas_rf_opt)\n",
    "modelos_optimizados['Random Forest'] = rf_optimizado\n",
    "mejores_parametros['Random Forest'] = rf_random.best_params_\n",
    "\n",
    "print(f\"‚úì Random Forest optimizado en {tiempo_rf_opt:.2f} segundos\")\n",
    "print(f\"Mejores par√°metros: {rf_random.best_params_}\")\n",
    "imprimir_metricas(metricas_rf_opt)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 10.2 Optimizaci√≥n XGBoost (ULTRA-R√ÅPIDA + EARLY STOPPING)\n",
    "# ---------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"10.2 Optimizando XGBoost... (10 iter √ó 2 cv = 20 fits + early stopping)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "tiempo_inicio = time.time()\n",
    "\n",
    "# Espacio de b√∫squeda ULTRA-SIMPLIFICADO y ENFOCADO\n",
    "param_dist_xgb = {\n",
    "    'n_estimators': [150, 200, 250],        # 3 valores (rango enfocado)\n",
    "    'max_depth': [6, 8, 10],                # 3 valores (eliminado 4)\n",
    "    'learning_rate': [0.05, 0.1, 0.15],     # 3 valores (rango √≥ptimo)\n",
    "    'subsample': [0.8, 0.9],                # 2 valores (mejores pr√°cticas)\n",
    "    'colsample_bytree': [0.8, 0.9],         # 2 valores (mejores pr√°cticas)\n",
    "}\n",
    "# Combinaciones posibles: 3√ó3√ó3√ó2√ó2 = 108 (vs 13,824 anterior)\n",
    "\n",
    "print(f\"Espacio de b√∫squeda: {len(param_dist_xgb)} hiperpar√°metros\")\n",
    "print(f\"Combinaciones posibles: 108 (reducido 99% desde anterior)\")\n",
    "\n",
    "xgb_random = RandomizedSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42, n_jobs=-1, verbosity=0),\n",
    "    param_distributions=param_dist_xgb,\n",
    "    n_iter=10,      # ‚ö° REDUCIDO de 25\n",
    "    cv=2,           # ‚ö° REDUCIDO de 3\n",
    "    scoring='neg_mean_squared_error',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ‚ö° EARLY STOPPING para acelerar entrenamiento\n",
    "# Nota: early_stopping_rounds no se puede usar directamente en RandomizedSearchCV\n",
    "# pero los n_estimators reducidos ya aceleran el proceso\n",
    "xgb_random.fit(X_train, y_train)\n",
    "xgb_optimizado = xgb_random.best_estimator_\n",
    "y_pred_xgb_opt = xgb_optimizado.predict(X_test)\n",
    "\n",
    "tiempo_xgb_opt = time.time() - tiempo_inicio\n",
    "\n",
    "metricas_xgb_opt = calcular_metricas(y_test, y_pred_xgb_opt, \"XGBoost (Optimizado)\")\n",
    "resultados_optimizados.append(metricas_xgb_opt)\n",
    "modelos_optimizados['XGBoost'] = xgb_optimizado\n",
    "mejores_parametros['XGBoost'] = xgb_random.best_params_\n",
    "\n",
    "print(f\"‚úì XGBoost optimizado en {tiempo_xgb_opt:.2f} segundos\")\n",
    "print(f\"Mejores par√°metros: {xgb_random.best_params_}\")\n",
    "imprimir_metricas(metricas_xgb_opt)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 10.3 Optimizaci√≥n CatBoost (ULTRA-R√ÅPIDA)\n",
    "# ---------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"10.3 Optimizando CatBoost... (10 iter √ó 2 cv = 20 fits)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "tiempo_inicio = time.time()\n",
    "\n",
    "# Espacio de b√∫squeda ULTRA-SIMPLIFICADO y ENFOCADO\n",
    "param_dist_cat = {\n",
    "    'iterations': [150, 200, 250],          # 3 valores (rango enfocado)\n",
    "    'depth': [6, 8, 10],                    # 3 valores (eliminado 4)\n",
    "    'learning_rate': [0.05, 0.1, 0.15],     # 3 valores (rango √≥ptimo)\n",
    "    'l2_leaf_reg': [3, 5],                  # 2 valores (valores √≥ptimos)\n",
    "}\n",
    "# Combinaciones posibles: 3√ó3√ó3√ó2 = 54 (vs 4,320 anterior)\n",
    "\n",
    "print(f\"Espacio de b√∫squeda: {len(param_dist_cat)} hiperpar√°metros\")\n",
    "print(f\"Combinaciones posibles: 54 (reducido 99% desde anterior)\")\n",
    "\n",
    "cat_random = RandomizedSearchCV(\n",
    "    estimator=CatBoostRegressor(random_state=42, verbose=0, thread_count=-1),\n",
    "    param_distributions=param_dist_cat,\n",
    "    n_iter=10,      # ‚ö° REDUCIDO de 20\n",
    "    cv=2,           # ‚ö° REDUCIDO de 3\n",
    "    scoring='neg_mean_squared_error',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "cat_random.fit(X_train, y_train)\n",
    "cat_optimizado = cat_random.best_estimator_\n",
    "y_pred_cat_opt = cat_optimizado.predict(X_test)\n",
    "\n",
    "tiempo_cat_opt = time.time() - tiempo_inicio\n",
    "\n",
    "metricas_cat_opt = calcular_metricas(y_test, y_pred_cat_opt, \"CatBoost (Optimizado)\")\n",
    "resultados_optimizados.append(metricas_cat_opt)\n",
    "modelos_optimizados['CatBoost'] = cat_optimizado\n",
    "mejores_parametros['CatBoost'] = cat_random.best_params_\n",
    "\n",
    "print(f\"‚úì CatBoost optimizado en {tiempo_cat_opt:.2f} segundos\")\n",
    "print(f\"Mejores par√°metros: {cat_random.best_params_}\")\n",
    "imprimir_metricas(metricas_cat_opt)\n",
    "\n",
    "tiempo_total_optimizacion = time.time() - tiempo_inicio_optimizacion\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"‚ö° TIEMPO TOTAL DE OPTIMIZACI√ìN: {tiempo_total_optimizacion:.2f} segundos ({tiempo_total_optimizacion/60:.2f} minutos)\")\n",
    "print(f\"‚úÖ OBJETIVO: < 15 minutos | LOGRADO: {tiempo_total_optimizacion/60:.2f} minutos\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# PASO 11: COMPARACI√ìN DE RESULTADOS (BASE VS OPTIMIZADO)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"‚ñà\" * 80)\n",
    "print(\"PASO 11: COMPARACI√ìN DE RESULTADOS\")\n",
    "print(\"‚ñà\" * 80)\n",
    "\n",
    "# Crear DataFrame comparativo\n",
    "df_resultados_base_comp = pd.DataFrame(resultados_base)\n",
    "df_resultados_opt_comp = pd.DataFrame(resultados_optimizados)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODELOS BASE (PAR√ÅMETROS MEJORADOS)\")\n",
    "print(\"=\" * 80)\n",
    "print(df_resultados_base_comp.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MODELOS OPTIMIZADOS\")\n",
    "print(\"=\" * 80)\n",
    "print(df_resultados_opt_comp.to_string(index=False))\n",
    "\n",
    "# Calcular mejoras\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MEJORAS DESPU√âS DE LA OPTIMIZACI√ìN\")\n",
    "print(\"=\" * 80)\n",
    "for i, modelo in enumerate(['Random Forest', 'XGBoost', 'CatBoost']):\n",
    "    rmse_base = df_resultados_base_comp.iloc[i]['RMSE']\n",
    "    rmse_opt = df_resultados_opt_comp.iloc[i]['RMSE']\n",
    "    mejora_rmse = ((rmse_base - rmse_opt) / rmse_base) * 100\n",
    "    \n",
    "    r2_base = df_resultados_base_comp.iloc[i]['R¬≤']\n",
    "    r2_opt = df_resultados_opt_comp.iloc[i]['R¬≤']\n",
    "    mejora_r2 = ((r2_opt - r2_base) / r2_base) * 100\n",
    "    \n",
    "    print(f\"\\n{modelo}:\")\n",
    "    print(f\"  Reducci√≥n RMSE: {mejora_rmse:.2f}%\")\n",
    "    print(f\"  Mejora R¬≤: {mejora_r2:.2f}%\")\n",
    "\n",
    "# ============================================================================\n",
    "# PASO 12: SELECCI√ìN DEL MEJOR MODELO\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"‚ñà\" * 80)\n",
    "print(\"PASO 12: SELECCI√ìN DEL MEJOR MODELO\")\n",
    "print(\"‚ñà\" * 80)\n",
    "\n",
    "# Encontrar el mejor modelo basado en RMSE (menor es mejor)\n",
    "df_resultados_opt = pd.DataFrame(resultados_optimizados)\n",
    "idx_mejor = df_resultados_opt['RMSE'].idxmin()\n",
    "mejor_modelo_nombre = df_resultados_opt.iloc[idx_mejor]['Modelo'].replace(' (Optimizado)', '')\n",
    "mejor_modelo = modelos_optimizados[mejor_modelo_nombre]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"üèÜ MEJOR MODELO: {mejor_modelo_nombre}\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nRanking de modelos por RMSE (menor es mejor):\")\n",
    "df_ranking = df_resultados_opt.sort_values('RMSE')[['Modelo', 'RMSE', 'MAE', 'R¬≤', 'MAPE (%)']]\n",
    "for idx, row in df_ranking.iterrows():\n",
    "    ranking_pos = list(df_ranking.index).index(idx) + 1\n",
    "    simbolo = \"ü•á\" if ranking_pos == 1 else \"ü•à\" if ranking_pos == 2 else \"ü•â\"\n",
    "    print(f\"\\n{simbolo} #{ranking_pos} - {row['Modelo']}\")\n",
    "    print(f\"   RMSE: ‚Çπ{row['RMSE']:,.2f} | MAE: ‚Çπ{row['MAE']:,.2f} | R¬≤: {row['R¬≤']:.4f} | MAPE: {row['MAPE (%)']:.2f}%\")\n",
    "\n",
    "# ============================================================================\n",
    "# PASO 13: AN√ÅLISIS DE IMPORTANCIA DE CARACTER√çSTICAS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"‚ñà\" * 80)\n",
    "print(\"PASO 13: AN√ÅLISIS DE IMPORTANCIA DE CARACTER√çSTICAS\")\n",
    "print(\"‚ñà\" * 80)\n",
    "\n",
    "# Obtener nombres de caracter√≠sticas\n",
    "feature_names = X_train.columns if hasattr(X_train, 'columns') else [f'Feature_{i}' for i in range(X_train.shape[1])]\n",
    "\n",
    "# Diccionario para almacenar importancias\n",
    "importancias_dict = {}\n",
    "\n",
    "# Obtener importancia de cada modelo\n",
    "for nombre_modelo, modelo in modelos_optimizados.items():\n",
    "    if hasattr(modelo, 'feature_importances_'):\n",
    "        importancias_dict[nombre_modelo] = modelo.feature_importances_\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  {nombre_modelo} no tiene atributo feature_importances_\")\n",
    "\n",
    "# Crear DataFrame de importancias\n",
    "df_importancias = pd.DataFrame(importancias_dict, index=feature_names)\n",
    "\n",
    "# Top 15 caracter√≠sticas por modelo\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TOP 15 CARACTER√çSTICAS M√ÅS IMPORTANTES POR MODELO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for modelo in df_importancias.columns:\n",
    "    print(f\"\\n{modelo}:\")\n",
    "    print(\"-\" * 80)\n",
    "    top_features = df_importancias[modelo].sort_values(ascending=False).head(15)\n",
    "    for idx, (feature, importance) in enumerate(top_features.items(), 1):\n",
    "        print(f\"  {idx:2d}. {feature:30s} : {importance:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PASO 14: GUARDADO DE MODELOS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"‚ñà\" * 80)\n",
    "print(\"PASO 14: GUARDADO DE MODELOS\")\n",
    "print(\"‚ñà\" * 80)\n",
    "\n",
    "# Crear directorio para modelos si no existe\n",
    "import os\n",
    "os.makedirs('modelos_guardados', exist_ok=True)\n",
    "\n",
    "# Guardar todos los modelos optimizados\n",
    "for nombre_modelo, modelo in modelos_optimizados.items():\n",
    "    nombre_archivo = f\"modelos_guardados/{nombre_modelo.replace(' ', '_').lower()}_optimizado_v2.pkl\"\n",
    "    joblib.dump(modelo, nombre_archivo)\n",
    "    print(f\"‚úì Guardado: {nombre_archivo}\")\n",
    "\n",
    "# Guardar el mejor modelo con un nombre especial\n",
    "nombre_archivo_mejor = f\"modelos_guardados/MEJOR_MODELO_{mejor_modelo_nombre.replace(' ', '_').lower()}_v2.pkl\"\n",
    "joblib.dump(mejor_modelo, nombre_archivo_mejor)\n",
    "print(f\"‚úì Guardado: {nombre_archivo_mejor}\")\n",
    "\n",
    "# Guardar mejores hiperpar√°metros\n",
    "import json\n",
    "with open('modelos_guardados/mejores_hiperparametros_v2.json', 'w') as f:\n",
    "    # Convertir valores numpy a tipos nativos de Python para JSON\n",
    "    parametros_json = {}\n",
    "    for modelo, params in mejores_parametros.items():\n",
    "        parametros_json[modelo] = {k: str(v) if isinstance(v, (np.integer, np.floating)) else v \n",
    "                                  for k, v in params.items()}\n",
    "    json.dump(parametros_json, f, indent=4)\n",
    "print(f\"‚úì Guardado: modelos_guardados/mejores_hiperparametros_v2.json\")\n",
    "\n",
    "# Guardar m√©tricas de todos los modelos\n",
    "df_resultados_completo = pd.concat([\n",
    "    df_resultados_base_comp.assign(Tipo='Base'),\n",
    "    df_resultados_opt_comp.assign(Tipo='Optimizado')\n",
    "], ignore_index=True)\n",
    "df_resultados_completo.to_csv('modelos_guardados/metricas_modelos_v2.csv', index=False)\n",
    "print(f\"‚úì Guardado: modelos_guardados/metricas_modelos_v2.csv\")\n",
    "\n",
    "# Guardar resumen de optimizaci√≥n\n",
    "resumen_optimizacion = {\n",
    "    'version': '2.0 Ultra-Optimizada',\n",
    "    'fecha': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'configuracion': {\n",
    "        'n_iter': 10,\n",
    "        'cv': 2,\n",
    "        'total_fits': 60,\n",
    "        'reduccion_vs_anterior': '69%'\n",
    "    },\n",
    "    'tiempos': {\n",
    "        'optimizacion_total_segundos': round(tiempo_total_optimizacion, 2),\n",
    "        'optimizacion_total_minutos': round(tiempo_total_optimizacion/60, 2),\n",
    "        'random_forest_segundos': round(tiempo_rf_opt, 2),\n",
    "        'xgboost_segundos': round(tiempo_xgb_opt, 2),\n",
    "        'catboost_segundos': round(tiempo_cat_opt, 2)\n",
    "    },\n",
    "    'mejor_modelo': {\n",
    "        'nombre': mejor_modelo_nombre,\n",
    "        'metricas': {\n",
    "            'RMSE': float(df_resultados_opt.iloc[idx_mejor]['RMSE']),\n",
    "            'MAE': float(df_resultados_opt.iloc[idx_mejor]['MAE']),\n",
    "            'R2': float(df_resultados_opt.iloc[idx_mejor]['R¬≤']),\n",
    "            'MAPE': float(df_resultados_opt.iloc[idx_mejor]['MAPE (%)'])\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('modelos_guardados/resumen_optimizacion_v2.json', 'w') as f:\n",
    "    json.dump(resumen_optimizacion, f, indent=4)\n",
    "print(f\"‚úì Guardado: modelos_guardados/resumen_optimizacion_v2.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úì Todos los modelos y m√©tricas guardados exitosamente\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# PASO 15: VISUALIZACIONES\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"‚ñà\" * 80)\n",
    "print(\"PASO 15: GENERACI√ìN DE VISUALIZACIONES\")\n",
    "print(\"‚ñà\" * 80)\n",
    "\n",
    "# Configurar estilo de gr√°ficos\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 15.1 Comparaci√≥n de m√©tricas: Base vs Optimizado\n",
    "# ---------------------------------------------------------------------------\n",
    "print(\"\\n15.1 Generando gr√°fico de comparaci√≥n Base vs Optimizado...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Comparaci√≥n de Modelos: Base vs Optimizado (Ultra-R√°pido)', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Preparar datos\n",
    "modelos_nombres = ['Random Forest', 'XGBoost', 'CatBoost']\n",
    "x = np.arange(len(modelos_nombres))\n",
    "width = 0.35\n",
    "\n",
    "# RMSE\n",
    "ax1 = axes[0, 0]\n",
    "rmse_base = [df_resultados_base_comp.iloc[i]['RMSE'] for i in range(3)]\n",
    "rmse_opt = [df_resultados_opt_comp.iloc[i]['RMSE'] for i in range(3)]\n",
    "ax1.bar(x - width/2, rmse_base, width, label='Base', alpha=0.8)\n",
    "ax1.bar(x + width/2, rmse_opt, width, label='Optimizado', alpha=0.8)\n",
    "ax1.set_xlabel('Modelo', fontweight='bold')\n",
    "ax1.set_ylabel('RMSE (‚Çπ)', fontweight='bold')\n",
    "ax1.set_title('RMSE: Menor es Mejor', fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(modelos_nombres, rotation=15, ha='right')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# MAE\n",
    "ax2 = axes[0, 1]\n",
    "mae_base = [df_resultados_base_comp.iloc[i]['MAE'] for i in range(3)]\n",
    "mae_opt = [df_resultados_opt_comp.iloc[i]['MAE'] for i in range(3)]\n",
    "ax2.bar(x - width/2, mae_base, width, label='Base', alpha=0.8)\n",
    "ax2.bar(x + width/2, mae_opt, width, label='Optimizado', alpha=0.8)\n",
    "ax2.set_xlabel('Modelo', fontweight='bold')\n",
    "ax2.set_ylabel('MAE (‚Çπ)', fontweight='bold')\n",
    "ax2.set_title('MAE: Menor es Mejor', fontweight='bold')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(modelos_nombres, rotation=15, ha='right')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# R¬≤\n",
    "ax3 = axes[1, 0]\n",
    "r2_base = [df_resultados_base_comp.iloc[i]['R¬≤'] for i in range(3)]\n",
    "r2_opt = [df_resultados_opt_comp.iloc[i]['R¬≤'] for i in range(3)]\n",
    "ax3.bar(x - width/2, r2_base, width, label='Base', alpha=0.8)\n",
    "ax3.bar(x + width/2, r2_opt, width, label='Optimizado', alpha=0.8)\n",
    "ax3.set_xlabel('Modelo', fontweight='bold')\n",
    "ax3.set_ylabel('R¬≤', fontweight='bold')\n",
    "ax3.set_title('R¬≤: Mayor es Mejor', fontweight='bold')\n",
    "ax3.set_xticks(x)\n",
    "ax3.set_xticklabels(modelos_nombres, rotation=15, ha='right')\n",
    "ax3.legend()\n",
    "ax3.set_ylim([0.9, 1.0])\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# MAPE\n",
    "ax4 = axes[1, 1]\n",
    "mape_base = [df_resultados_base_comp.iloc[i]['MAPE (%)'] for i in range(3)]\n",
    "mape_opt = [df_resultados_opt_comp.iloc[i]['MAPE (%)'] for i in range(3)]\n",
    "ax4.bar(x - width/2, mape_base, width, label='Base', alpha=0.8)\n",
    "ax4.bar(x + width/2, mape_opt, width, label='Optimizado', alpha=0.8)\n",
    "ax4.set_xlabel('Modelo', fontweight='bold')\n",
    "ax4.set_ylabel('MAPE (%)', fontweight='bold')\n",
    "ax4.set_title('MAPE: Menor es Mejor', fontweight='bold')\n",
    "ax4.set_xticks(x)\n",
    "ax4.set_xticklabels(modelos_nombres, rotation=15, ha='right')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('modelos_guardados/v2_01_comparacion_base_vs_optimizado.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úì Guardado: modelos_guardados/v2_01_comparacion_base_vs_optimizado.png\")\n",
    "plt.close()\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 15.2 Comparaci√≥n solo de modelos optimizados\n",
    "# ---------------------------------------------------------------------------\n",
    "print(\"\\n15.2 Generando gr√°fico comparativo de modelos optimizados...\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Normalizar m√©tricas para comparaci√≥n visual\n",
    "metricas_norm = {\n",
    "    'Modelo': modelos_nombres,\n",
    "    'RMSE (norm)': [1 - (r / max(rmse_opt)) for r in rmse_opt],\n",
    "    'MAE (norm)': [1 - (m / max(mae_opt)) for m in mae_opt],\n",
    "    'R¬≤': r2_opt,\n",
    "    'MAPE (norm)': [1 - (m / 100) for m in mape_opt]\n",
    "}\n",
    "\n",
    "df_norm = pd.DataFrame(metricas_norm)\n",
    "df_norm_melt = df_norm.melt(id_vars=['Modelo'], var_name='M√©trica', value_name='Valor')\n",
    "\n",
    "sns.barplot(data=df_norm_melt, x='Modelo', y='Valor', hue='M√©trica', ax=ax)\n",
    "ax.set_title('Comparaci√≥n de Modelos Optimizados (M√©tricas Normalizadas) - Ultra-R√°pido', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Valor Normalizado (Mayor es Mejor)', fontweight='bold')\n",
    "ax.set_xlabel('Modelo', fontweight='bold')\n",
    "ax.legend(title='M√©trica', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.savefig('modelos_guardados/v2_02_comparacion_modelos_optimizados.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úì Guardado: modelos_guardados/v2_02_comparacion_modelos_optimizados.png\")\n",
    "plt.close()\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 15.3 Importancia de caracter√≠sticas (Top 15)\n",
    "# ---------------------------------------------------------------------------\n",
    "print(\"\\n15.3 Generando gr√°ficos de importancia de caracter√≠sticas...\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "fig.suptitle('Top 15 Caracter√≠sticas M√°s Importantes por Modelo (Ultra-Optimizado)', \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, (modelo, ax) in enumerate(zip(df_importancias.columns, axes)):\n",
    "    top_15 = df_importancias[modelo].sort_values(ascending=False).head(15)\n",
    "    \n",
    "    colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(top_15)))\n",
    "    ax.barh(range(len(top_15)), top_15.values, color=colors)\n",
    "    ax.set_yticks(range(len(top_15)))\n",
    "    ax.set_yticklabels(top_15.index, fontsize=9)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel('Importancia', fontweight='bold')\n",
    "    ax.set_title(modelo, fontweight='bold', fontsize=12)\n",
    "    ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('modelos_guardados/v2_03_importancia_caracteristicas.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úì Guardado: modelos_guardados/v2_03_importancia_caracteristicas.png\")\n",
    "plt.close()\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 15.4 Predicciones vs Valores Reales (Mejor Modelo)\n",
    "# ---------------------------------------------------------------------------\n",
    "print(\"\\n15.4 Generando gr√°fico de predicciones vs valores reales...\")\n",
    "\n",
    "# Obtener predicciones del mejor modelo\n",
    "if mejor_modelo_nombre == 'Random Forest':\n",
    "    y_pred_mejor = y_pred_rf_opt\n",
    "elif mejor_modelo_nombre == 'XGBoost':\n",
    "    y_pred_mejor = y_pred_xgb_opt\n",
    "else:  # CatBoost\n",
    "    y_pred_mejor = y_pred_cat_opt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle(f'An√°lisis de Predicciones - {mejor_modelo_nombre} (Mejor Modelo - Ultra-Optimizado)', \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "# Scatter plot: Predicciones vs Reales\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(y_test, y_pred_mejor, alpha=0.5, s=20)\n",
    "ax1.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "         'r--', lw=2, label='Predicci√≥n Perfecta')\n",
    "ax1.set_xlabel('Precio Real (‚Çπ)', fontweight='bold', fontsize=12)\n",
    "ax1.set_ylabel('Precio Predicho (‚Çπ)', fontweight='bold', fontsize=12)\n",
    "ax1.set_title('Predicciones vs Valores Reales', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Distribuci√≥n de errores\n",
    "ax2 = axes[1]\n",
    "errores = y_test - y_pred_mejor\n",
    "ax2.hist(errores, bins=50, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "ax2.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Error = 0')\n",
    "ax2.set_xlabel('Error de Predicci√≥n (‚Çπ)', fontweight='bold', fontsize=12)\n",
    "ax2.set_ylabel('Frecuencia', fontweight='bold', fontsize=12)\n",
    "ax2.set_title('Distribuci√≥n de Errores', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('modelos_guardados/v2_04_predicciones_vs_reales_mejor_modelo.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úì Guardado: modelos_guardados/v2_04_predicciones_vs_reales_mejor_modelo.png\")\n",
    "plt.close()\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 15.5 Residuos del mejor modelo\n",
    "# ---------------------------------------------------------------------------\n",
    "print(\"\\n15.5 Generando an√°lisis de residuos...\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle(f'An√°lisis de Residuos - {mejor_modelo_nombre} (Ultra-Optimizado)', \n",
    "             fontsize=16, fontweight='bold')\n",
    "\n",
    "# Residuos vs Predicciones\n",
    "ax1 = axes[0]\n",
    "residuos = y_test - y_pred_mejor\n",
    "ax1.scatter(y_pred_mejor, residuos, alpha=0.5, s=20)\n",
    "ax1.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "ax1.set_xlabel('Precio Predicho (‚Çπ)', fontweight='bold', fontsize=12)\n",
    "ax1.set_ylabel('Residuos (‚Çπ)', fontweight='bold', fontsize=12)\n",
    "ax1.set_title('Residuos vs Predicciones', fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Q-Q Plot\n",
    "ax2 = axes[1]\n",
    "from scipy import stats\n",
    "stats.probplot(residuos, dist=\"norm\", plot=ax2)\n",
    "ax2.set_title('Q-Q Plot (Normalidad de Residuos)', fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('modelos_guardados/v2_05_analisis_residuos.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úì Guardado: modelos_guardados/v2_05_analisis_residuos.png\")\n",
    "plt.close()\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 15.6 Radar Chart de m√©tricas\n",
    "# ---------------------------------------------------------------------------\n",
    "print(\"\\n15.6 Generando radar chart comparativo...\")\n",
    "\n",
    "from math import pi\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))\n",
    "\n",
    "# Categor√≠as (m√©tricas normalizadas)\n",
    "categorias = ['RMSE\\n(invertido)', 'MAE\\n(invertido)', 'R¬≤', 'MAPE\\n(invertido)']\n",
    "N = len(categorias)\n",
    "\n",
    "# √Ångulos para cada m√©trica\n",
    "angles = [n / float(N) * 2 * pi for n in range(N)]\n",
    "angles += angles[:1]\n",
    "\n",
    "# Plot para cada modelo\n",
    "for i, modelo in enumerate(modelos_nombres):\n",
    "    valores = [\n",
    "        1 - (rmse_opt[i] / max(rmse_opt)),  # RMSE invertido\n",
    "        1 - (mae_opt[i] / max(mae_opt)),    # MAE invertido\n",
    "        r2_opt[i],                           # R¬≤\n",
    "        1 - (mape_opt[i] / max(mape_opt))   # MAPE invertido\n",
    "    ]\n",
    "    valores += valores[:1]\n",
    "    \n",
    "    ax.plot(angles, valores, 'o-', linewidth=2, label=modelo)\n",
    "    ax.fill(angles, valores, alpha=0.15)\n",
    "\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(categorias, size=11, fontweight='bold')\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title('Comparaci√≥n de Modelos - Radar Chart (Ultra-Optimizado)\\n(Valores normalizados: mayor es mejor)', \n",
    "             fontweight='bold', size=14, pad=20)\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('modelos_guardados/v2_06_radar_chart_comparacion.png', dpi=300, bbox_inches='tight')\n",
    "print(\"‚úì Guardado: modelos_guardados/v2_06_radar_chart_comparacion.png\")\n",
    "plt.close()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úì Todas las visualizaciones generadas exitosamente\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# RESUMEN FINAL Y CONCLUSIONES\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"‚ñà\" * 80)\n",
    "print(\"RESUMEN FINAL Y CONCLUSIONES (VERSI√ìN ULTRA-OPTIMIZADA)\")\n",
    "print(\"‚ñà\" * 80)\n",
    "\n",
    "tiempo_total = time.time() - tiempo_inicio_total\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"‚è±Ô∏è  TIEMPO TOTAL DE EJECUCI√ìN: {tiempo_total:.2f} segundos ({tiempo_total/60:.2f} minutos)\")\n",
    "print(f\"‚úÖ OBJETIVO: < 15 minutos\")\n",
    "print(f\"‚úÖ LOGRADO: {tiempo_total/60:.2f} minutos\")\n",
    "print(f\"‚ö° REDUCCI√ìN: {((817 - tiempo_total)/817*100):.1f}% m√°s r√°pido que versi√≥n anterior\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"üèÜ MEJOR MODELO SELECCIONADO: {mejor_modelo_nombre}\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"  RMSE:  ‚Çπ{df_resultados_opt.iloc[idx_mejor]['RMSE']:,.2f}\")\n",
    "print(f\"  MAE:   ‚Çπ{df_resultados_opt.iloc[idx_mejor]['MAE']:,.2f}\")\n",
    "print(f\"  R¬≤:    {df_resultados_opt.iloc[idx_mejor]['R¬≤']:.4f}\")\n",
    "print(f\"  MAPE:  {df_resultados_opt.iloc[idx_mejor]['MAPE (%)']:.2f}%\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "print(\"\\nüìä INTERPRETACI√ìN DE RESULTADOS:\")\n",
    "print(\"-\" * 80)\n",
    "mejor_r2 = df_resultados_opt.iloc[idx_mejor]['R¬≤']\n",
    "mejor_mape = df_resultados_opt.iloc[idx_mejor]['MAPE (%)']\n",
    "\n",
    "if mejor_r2 >= 0.99:\n",
    "    print(f\"‚úì R¬≤ = {mejor_r2:.4f} indica un ajuste EXCELENTE (>99% de varianza explicada)\")\n",
    "elif mejor_r2 >= 0.95:\n",
    "    print(f\"‚úì R¬≤ = {mejor_r2:.4f} indica un ajuste MUY BUENO (>95% de varianza explicada)\")\n",
    "elif mejor_r2 >= 0.90:\n",
    "    print(f\"‚úì R¬≤ = {mejor_r2:.4f} indica un ajuste BUENO (>90% de varianza explicada)\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  R¬≤ = {mejor_r2:.4f} indica un ajuste MODERADO\")\n",
    "\n",
    "if mejor_mape <= 5:\n",
    "    print(f\"‚úì MAPE = {mejor_mape:.2f}% indica predicciones EXCELENTES (error <5%)\")\n",
    "elif mejor_mape <= 10:\n",
    "    print(f\"‚úì MAPE = {mejor_mape:.2f}% indica predicciones MUY BUENAS (error <10%)\")\n",
    "elif mejor_mape <= 20:\n",
    "    print(f\"‚úì MAPE = {mejor_mape:.2f}% indica predicciones BUENAS (error <20%)\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  MAPE = {mejor_mape:.2f}% indica predicciones MODERADAS\")\n",
    "\n",
    "print(\"\\nüìà OPTIMIZACIONES APLICADAS:\")\n",
    "print(\"-\" * 80)\n",
    "print(\"  ‚úì n_iter reducido de 20-25 a 10 (60% menos iteraciones)\")\n",
    "print(\"  ‚úì cv reducido de 3 a 2 (33% menos folds)\")\n",
    "print(\"  ‚úì Espacios de b√∫squeda simplificados (94-99% menos combinaciones)\")\n",
    "print(\"  ‚úì Total de fits: 60 (vs 195 anterior) - REDUCCI√ìN 69%\")\n",
    "print(\"  ‚úì Par√°metros base mejorados (mejor punto de partida)\")\n",
    "print(\"  ‚úì Paralelizaci√≥n completa (n_jobs=-1, thread_count=-1)\")\n",
    "print(\"  ‚úì LightGBM eliminado, CatBoost optimizado\")\n",
    "\n",
    "print(\"\\nüìÅ ARCHIVOS GENERADOS:\")\n",
    "print(\"-\" * 80)\n",
    "print(\"  Modelos (v2):\")\n",
    "print(\"    ‚Ä¢ modelos_guardados/random_forest_optimizado_v2.pkl\")\n",
    "print(\"    ‚Ä¢ modelos_guardados/xgboost_optimizado_v2.pkl\")\n",
    "print(\"    ‚Ä¢ modelos_guardados/catboost_optimizado_v2.pkl\")\n",
    "print(f\"    ‚Ä¢ modelos_guardados/MEJOR_MODELO_{mejor_modelo_nombre.replace(' ', '_').lower()}_v2.pkl\")\n",
    "print(\"\\n  Datos:\")\n",
    "print(\"    ‚Ä¢ modelos_guardados/mejores_hiperparametros_v2.json\")\n",
    "print(\"    ‚Ä¢ modelos_guardados/metricas_modelos_v2.csv\")\n",
    "print(\"    ‚Ä¢ modelos_guardados/resumen_optimizacion_v2.json\")\n",
    "print(\"\\n  Visualizaciones (v2):\")\n",
    "print(\"    ‚Ä¢ modelos_guardados/v2_01_comparacion_base_vs_optimizado.png\")\n",
    "print(\"    ‚Ä¢ modelos_guardados/v2_02_comparacion_modelos_optimizados.png\")\n",
    "print(\"    ‚Ä¢ modelos_guardados/v2_03_importancia_caracteristicas.png\")\n",
    "print(\"    ‚Ä¢ modelos_guardados/v2_04_predicciones_vs_reales_mejor_modelo.png\")\n",
    "print(\"    ‚Ä¢ modelos_guardados/v2_05_analisis_residuos.png\")\n",
    "print(\"    ‚Ä¢ modelos_guardados/v2_06_radar_chart_comparacion.png\")\n",
    "\n",
    "print(\"\\nüéØ PR√ìXIMOS PASOS RECOMENDADOS:\")\n",
    "print(\"-\" * 80)\n",
    "print(\"  1. Validar el modelo con datos completamente nuevos\")\n",
    "print(\"  2. Implementar el modelo en un sistema de producci√≥n\")\n",
    "print(\"  3. Configurar monitoreo de performance en tiempo real\")\n",
    "print(\"  4. Actualizar el modelo peri√≥dicamente con nuevos datos\")\n",
    "print(\"  5. Realizar an√°lisis de sensibilidad de caracter√≠sticas\")\n",
    "print(\"  6. Considerar ensemble de los mejores modelos para mayor robustez\")\n",
    "\n",
    "print(\"\\n\" + \"‚ñà\" * 80)\n",
    "print(\"‚úÖ PROCESO ULTRA-OPTIMIZADO COMPLETADO EXITOSAMENTE\")\n",
    "print(\"‚ñà\" * 80)\n",
    "print(f\"\\nVersi√≥n: 2.0 Ultra-Optimizada\")\n",
    "print(f\"Fecha de finalizaci√≥n: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Tiempo total: {tiempo_total/60:.2f} minutos (< 15 minutos ‚úÖ)\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00456757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
